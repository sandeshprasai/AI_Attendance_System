{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c79456",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install icrawler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd2c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SKIP] Robert Downey Jr: Already completed.\n",
      "[SKIP] Chris Evans: Already completed.\n",
      "[SKIP] Scarlett Johansson: Already completed.\n",
      "[SKIP] Tom Holland: Already completed.\n",
      "[SKIP] Zendaya: Already completed.\n",
      "[SKIP] Emma Watson: Already completed.\n",
      "[SKIP] Leonardo DiCaprio: Already completed.\n",
      "[SKIP] Brad Pitt: Already completed.\n",
      "[SKIP] Angelina Jolie: Already completed.\n",
      "[SKIP] Jennifer Lawrence: Already completed.\n",
      "[SKIP] Taylor Swift: Already completed.\n",
      "[SKIP] Ariana Grande: Already completed.\n",
      "[SKIP] Justin Bieber: Already completed.\n",
      "[SKIP] Selena Gomez: Already completed.\n",
      "[SKIP] Billie Eilish: Already completed.\n",
      "[SKIP] Ed Sheeran: Already completed.\n",
      "[SKIP] Beyoncé: Already completed.\n",
      "[SKIP] Rihanna: Already completed.\n",
      "[SKIP] Drake: Already completed.\n",
      "[SKIP] Shawn Mendes: Already completed.\n",
      "[SKIP] Lionel Messi: Already completed.\n",
      "[SKIP] Cristiano Ronaldo: Already completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:05,909 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:24:05,910 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:24:05,912 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:24:05,914 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:24:05,916 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Downloading images for: Neymar Jr\n",
      "============================================================\n",
      "[INFO] Neymar Jr: Found 0 existing images\n",
      "[INFO] Neymar Jr: Attempt 1\n",
      "[INFO] Using Google\n",
      "   [SEARCH] Neymar Jr headshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:06,974 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+headshot&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:24:10,917 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:24:10,918 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:24:10,919 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:24:10,920 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:24:11,921 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:17,579 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:24:17,580 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:24:17,581 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:24:17,583 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:24:17,584 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:18,718 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+photo&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:24:22,587 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:24:22,588 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:24:22,588 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:24:22,589 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:24:23,590 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:31,357 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:24:31,357 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:24:31,358 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:24:31,360 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:24:31,361 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr professional photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:32,107 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+professional+photo&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:24:36,364 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:24:36,365 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:24:36,365 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:24:36,367 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:24:37,367 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:42,254 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:24:42,255 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:24:42,257 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:24:42,258 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:24:42,259 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr event photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:43,333 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+event+photo&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:24:47,261 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:24:47,265 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:24:47,265 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:24:47,269 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:24:48,266 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:54,170 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:24:54,172 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:24:54,173 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:24:54,177 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:24:54,178 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr still\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:24:54,977 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+still&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:24:59,181 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:24:59,183 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:24:59,184 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:24:59,187 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:00,184 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:04,944 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:25:04,945 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:25:04,947 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:25:04,949 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:25:04,951 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr candid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:05,992 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+candid&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:25:09,953 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:25:09,955 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:25:09,955 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:25:09,958 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:10,956 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:18,255 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:25:18,256 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:25:18,257 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:25:18,258 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:25:18,260 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr close up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:19,138 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+close+up&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:25:23,262 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:25:23,264 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:25:23,264 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:25:23,266 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:24,265 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:32,026 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:25:32,027 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:25:32,028 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:25:32,029 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:25:32,031 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr face\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:32,714 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+face&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:25:37,034 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:25:37,036 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:25:37,036 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:37,039 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:25:38,037 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:41,936 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:25:41,937 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:25:41,938 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:25:41,941 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:25:41,942 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr portrait\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:42,760 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+portrait&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:25:46,947 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:25:46,950 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:25:46,951 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:25:46,953 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:47,951 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:52,422 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:25:52,423 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:25:52,424 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:25:52,425 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:25:52,427 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr movie still\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:25:53,488 - INFO - parser - parsing result page https://www.google.com/search?q=Neymar+Jr+movie+still&ijn=0&start=0&tbs=&tbm=isch\n",
      "Exception in thread parser-001:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1075, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\threading.py\", line 1012, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\admin\\AppData\\Roaming\\Python\\Python312\\site-packages\\icrawler\\parser.py\", line 93, in worker_exec\n",
      "    for task in self.parse(response, **kwargs):\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: 'NoneType' object is not iterable\n",
      "2025-09-06 15:25:57,430 - INFO - downloader - no more download task for thread downloader-001\n",
      "2025-09-06 15:25:57,431 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:25:57,433 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:25:57,435 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:25:58,433 - INFO - icrawler.crawler - Crawling task done!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +0 unique → 0/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:26:05,646 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:26:05,648 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:26:05,649 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:26:05,652 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:26:05,654 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using Bing\n",
      "   [SEARCH] Neymar Jr headshot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:26:06,271 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr headshot&first=0\n",
      "2025-09-06 15:26:06,623 - INFO - downloader - image #1\thttps://cdn.artphotolimited.com/images/5db6c870bd40b8127669aa45/1000x1000/portrait-neymar-jr-2.jpg\n",
      "2025-09-06 15:26:06,907 - ERROR - downloader - Response status code 403, file https://images.wallpapersden.com/image/download/neymar-jr_am5oaWWUmZqaraWkpJRobWllrWdpZWU.jpg\n",
      "2025-09-06 15:26:06,956 - INFO - downloader - image #2\thttps://i.pinimg.com/originals/a5/a9/7a/a5a97aa466ba033cbc21f4f029667995.jpg\n",
      "2025-09-06 15:26:07,481 - INFO - downloader - image #3\thttps://i.pinimg.com/originals/f2/e0/97/f2e0978be00813fc9da05e7e65de71a4.jpg\n",
      "2025-09-06 15:26:07,617 - INFO - downloader - image #4\thttps://c8.alamy.com/comp/2BB2XT4/neymar-barcelona-2BB2XT4.jpg\n",
      "2025-09-06 15:26:08,128 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1201977756/photo/neymar-junior-of-paris-saint-germain-getting-into-the-field-during-the-uefa-champions-league.jpg\n",
      "2025-09-06 15:26:08,411 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/109002433/photo/neymar-member-of-the-brazilian-u20-football-team-poses-during-a-portraits-session-during-the.jpg\n",
      "2025-09-06 15:26:09,553 - INFO - downloader - image #5\thttps://cdn.imago-images.de/bild/sp/1024294555/s.jpg\n",
      "2025-09-06 15:26:10,306 - INFO - downloader - image #6\thttps://inspirationseek.com/wp-content/uploads/2016/02/Neymar_08.jpg\n",
      "2025-09-06 15:26:10,478 - INFO - downloader - image #7\thttps://www.dailysia.com/wp-content/uploads/2020/02/Neymar-Jr_5.jpg\n",
      "2025-09-06 15:26:10,660 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1324125520/photo/neymar-jr-of-brazil-reacts-during-a-match-between-brazil-and-peru-as-part-of-group-b-of-copa.jpg\n",
      "2025-09-06 15:26:11,302 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1190271374/photo/neymar-jr-of-paris-saint-germain-looks-on-during-the-uefa-champions-league-group-a-match.jpg\n",
      "2025-09-06 15:26:11,545 - INFO - downloader - image #8\thttps://s-media-cache-ak0.pinimg.com/originals/61/33/e4/6133e4a83bdc36c0015b0674121f7b9e.jpg\n",
      "2025-09-06 15:26:11,883 - INFO - downloader - image #9\thttps://i.pinimg.com/736x/56/9c/5f/569c5fc77e3d94bb07bed78ded2cd68c.jpg\n",
      "2025-09-06 15:26:11,947 - INFO - downloader - image #10\thttps://i.pinimg.com/originals/50/ac/8c/50ac8c3eef32f4fbf6182cde88939556.jpg\n",
      "2025-09-06 15:26:12,298 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1311326216/photo/munich-germany-neymar-of-paris-saint-germain-looks-on-during-the-warm-up-prior-to-the-uefa.jpg\n",
      "2025-09-06 15:26:12,641 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1682933848/photo/riyadh-saudi-arabia-neymar-jr-of-al-hilal-looks-on-prior-to-the-match-between-al-hilal-and.jpg\n",
      "2025-09-06 15:26:12,774 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1465720529/photo/monaco-monaco-neymar-jr-of-psg-reacts-to-the-3-1-defeat-as-he-leaves-the-field-following-the.jpg\n",
      "2025-09-06 15:26:13,049 - ERROR - downloader - Response status code 400, file https://media.gettyimages.com/id/1458886017/photo/lens-france-neymar-jr-of-paris-saint-germain-reacts-after-scoring-during-the-round-of-32.jpg\n",
      "2025-09-06 15:26:13,799 - INFO - downloader - image #11\thttps://images7.alphacoders.com/929/thumb-1920-929652.jpg\n",
      "2025-09-06 15:26:13,895 - INFO - downloader - image #12\thttps://i.pinimg.com/736x/e8/39/0f/e8390fc49fd914281e5fc202372621d3.jpg\n",
      "2025-09-06 15:26:14,270 - INFO - downloader - image #13\thttps://i.pinimg.com/736x/97/ee/10/97ee10e729e159df242145f85432e864.jpg\n",
      "2025-09-06 15:26:14,275 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr headshot&first=20\n",
      "2025-09-06 15:26:14,659 - INFO - downloader - image #14\thttps://cdn.theathletic.com/app/uploads/2022/11/20180515/neymar-1-scaled-e1668987073617.jpg\n",
      "2025-09-06 15:26:15,212 - INFO - downloader - image #15\thttps://wallpapers.com/images/hd/neymar-jr-pro-shot-bw-ntpac5ynovnow4wo.jpg\n",
      "2025-09-06 15:26:15,849 - INFO - downloader - image #16\thttps://c8.alamy.com/comp/2BB2XRR/neymar-barcelona-2BB2XRR.jpg\n",
      "2025-09-06 15:26:16,253 - INFO - downloader - image #17\thttps://i.pinimg.com/736x/a1/ec/82/a1ec82c2f2744c01eb517afb580cb713.jpg\n",
      "2025-09-06 15:26:17,041 - INFO - downloader - image #18\thttps://e00-marca.uecdn.es/assets/multimedia/imagenes/2022/09/13/16630884605041.jpg\n",
      "2025-09-06 15:26:17,080 - INFO - downloader - image #19\thttps://i.pinimg.com/originals/2e/0b/a3/2e0ba3196afac1f863e0a4345724a49c.jpg\n",
      "2025-09-06 15:26:17,559 - INFO - downloader - image #20\thttps://i.pinimg.com/736x/92/bf/70/92bf702ad1e314d457d31cb455cde7bc.jpg\n",
      "2025-09-06 15:26:17,578 - INFO - downloader - image #21\thttps://i.pinimg.com/originals/18/8b/75/188b7525b47e032588b1f0a976ccb3b2.jpg\n",
      "2025-09-06 15:26:17,987 - INFO - downloader - image #22\thttps://i.pinimg.com/736x/05/1c/56/051c567ce25a2b61e9ba33423a5afff9.jpg\n",
      "2025-09-06 15:26:18,311 - INFO - downloader - image #23\thttps://assets.telegraphindia.com/abp/2022/Oct/1665737788_lead-image.jpg\n",
      "2025-09-06 15:26:18,397 - INFO - downloader - image #24\thttps://i.pinimg.com/736x/74/cf/59/74cf59ce57984d43f10c1fd3b0db641f.jpg\n",
      "2025-09-06 15:26:18,874 - INFO - downloader - image #25\thttps://i.pinimg.com/originals/d4/27/d1/d427d13e3aa6e02565634456a97850fe.jpg\n",
      "2025-09-06 15:26:18,918 - INFO - downloader - image #26\thttps://i.pinimg.com/originals/4f/58/e5/4f58e5c7eb30ba6017044a383a4e9332.jpg\n",
      "2025-09-06 15:26:18,952 - INFO - downloader - image #27\thttps://i.pinimg.com/originals/6e/d5/a0/6ed5a08ee4556ba9d068b652316b333f.jpg\n",
      "2025-09-06 15:26:19,277 - INFO - downloader - image #28\thttps://i.pinimg.com/originals/c5/8d/7c/c58d7cc94e9e2fb74fe1c67f2e8655a8.jpg\n",
      "2025-09-06 15:26:19,345 - INFO - downloader - image #29\thttps://i.pinimg.com/736x/2c/bf/8f/2cbf8f9466385bac2c6acf3a15e8119f.jpg\n",
      "2025-09-06 15:26:19,653 - INFO - downloader - image #30\thttps://i.pinimg.com/736x/e1/5e/0d/e15e0d459afc14bbd3a27a50845293da.jpg\n",
      "2025-09-06 15:26:19,818 - INFO - downloader - image #31\thttps://i.pinimg.com/736x/e1/5c/c4/e15cc4d1b9912b8be314b2d8ce7552c5.jpg\n",
      "2025-09-06 15:26:20,144 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr headshot&first=40\n",
      "2025-09-06 15:26:20,313 - INFO - downloader - image #32\thttps://i.pinimg.com/originals/89/1c/f3/891cf38094e72063caa0e35a2f6f063e.jpg\n",
      "2025-09-06 15:26:20,559 - INFO - downloader - image #33\thttps://editorial01.shutterstock.com/wm-preview-1500/9792995n/76340299/Shutterstock_9792995n.jpg\n",
      "2025-09-06 15:26:20,959 - INFO - downloader - image #34\thttps://i.pinimg.com/originals/cc/ab/4c/ccab4c02f70204a652b7f56f19e7c525.jpg\n",
      "2025-09-06 15:26:21,304 - INFO - downloader - image #35\thttps://i.pinimg.com/736x/d4/b0/91/d4b091ac4277c607187cddea571e1ecd.jpg\n",
      "2025-09-06 15:26:21,817 - INFO - downloader - image #36\thttps://i.pinimg.com/originals/f0/b0/38/f0b038b7171aada3573edbaa55ac53f5.jpg\n",
      "2025-09-06 15:26:21,888 - INFO - downloader - image #37\thttps://i.pinimg.com/736x/ea/5b/f4/ea5bf4712851c4a0477a046eb3d92dfa.jpg\n",
      "2025-09-06 15:26:22,327 - INFO - downloader - image #38\thttps://i.pinimg.com/736x/14/f5/b7/14f5b71a1718aa318b52a3df03dba4d5.jpg\n",
      "2025-09-06 15:26:22,716 - INFO - downloader - image #39\thttps://i.pinimg.com/736x/7f/34/d4/7f34d4b1ed2e94f469e928d5bdcc4595.jpg\n",
      "2025-09-06 15:26:23,105 - INFO - downloader - image #40\thttps://i.pinimg.com/originals/51/ea/73/51ea73fed075b84b4dfc2843c5984653.jpg\n",
      "2025-09-06 15:26:23,383 - INFO - downloader - image #41\thttps://stylecaster.com/wp-content/uploads/2023/06/neymar-cheating.jpg\n",
      "2025-09-06 15:26:23,515 - INFO - downloader - image #42\thttps://i.pinimg.com/originals/29/c5/04/29c5045320456455faa27fcb1b02a501.jpg\n",
      "2025-09-06 15:26:23,727 - INFO - downloader - image #43\thttps://i.pinimg.com/736x/5a/19/06/5a1906fbede3d2cb63bb0a3a324d5248.jpg\n",
      "2025-09-06 15:26:23,861 - INFO - downloader - image #44\thttps://i.pinimg.com/736x/63/94/09/63940939d45347c40afb35157291d3c4.jpg\n",
      "2025-09-06 15:26:24,250 - INFO - downloader - image #45\thttps://www.fcbarcelona.com/fcbarcelona/photo/2018/06/27/7c1862cf-87c4-48d5-9426-2ff781db545e/ggtMJOPs.jpg\n",
      "2025-09-06 15:26:24,521 - ERROR - downloader - Response status code 403, file https://c.ndtvimg.com/2022-06/priluo2_neymar-jr-afp_625x300_02_June_22.jpg\n",
      "2025-09-06 15:26:24,818 - INFO - downloader - image #46\thttps://i.pinimg.com/736x/bd/32/2a/bd322a416b5b15458d9d459dc4855324.jpg\n",
      "2025-09-06 15:26:24,908 - INFO - downloader - image #47\thttps://i.pinimg.com/originals/85/b5/f0/85b5f04289dc9e4aec9354cf2684d0a9.jpg\n",
      "2025-09-06 15:26:25,203 - INFO - downloader - image #48\thttps://i.pinimg.com/736x/18/91/58/1891587de9c35de3b785f4a621cb78cc.jpg\n",
      "2025-09-06 15:26:25,292 - INFO - downloader - image #49\thttps://i.pinimg.com/736x/c7/0b/0a/c70b0ade36f497b203c909be2162547c.jpg\n",
      "2025-09-06 15:26:25,676 - INFO - downloader - image #50\thttps://i.pinimg.com/736x/6f/79/dd/6f79ddbf38f23334762f7809050d03d3--neymar-jr-world-cup.jpg\n",
      "2025-09-06 15:26:26,022 - INFO - downloader - downloaded images reach max num, thread downloader-001 is ready to exit\n",
      "2025-09-06 15:26:26,022 - INFO - downloader - thread downloader-001 exit\n",
      "2025-09-06 15:26:26,341 - INFO - downloader - downloaded images reach max num, thread downloader-002 is ready to exit\n",
      "2025-09-06 15:26:26,342 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:26:26,666 - INFO - icrawler.crawler - Crawling task done!\n",
      "2025-09-06 15:26:27,204 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2025-09-06 15:26:27,205 - INFO - parser - thread parser-001 exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [INFO] +50 unique → 50/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:26:33,160 - INFO - icrawler.crawler - start crawling...\n",
      "2025-09-06 15:26:33,161 - INFO - icrawler.crawler - starting 1 feeder threads...\n",
      "2025-09-06 15:26:33,162 - INFO - feeder - thread feeder-001 exit\n",
      "2025-09-06 15:26:33,166 - INFO - icrawler.crawler - starting 1 parser threads...\n",
      "2025-09-06 15:26:33,167 - INFO - icrawler.crawler - starting 2 downloader threads...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [SEARCH] Neymar Jr photo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-06 15:26:33,777 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr photo&first=0\n",
      "2025-09-06 15:26:34,423 - INFO - downloader - image #1\thttps://images.ctfassets.net/3mv54pzvptwz/5eTv6hTyA1pqkFClYRn0qt/be626a573cbf1ee7e421b73f87ed6851/20221205_foto_GETTY_neymar_jr_jogo_brasil_x_coreia_copa_do_mundo__209_.jpg\n",
      "2025-09-06 15:26:36,249 - INFO - downloader - image #2\thttps://wallpaperaccess.com/full/1259911.jpg\n",
      "2025-09-06 15:26:38,175 - INFO - downloader - image #3\thttps://i.pinimg.com/originals/83/0c/4a/830c4ab38044c92c3daa37d70fa9147c.jpg\n",
      "2025-09-06 15:26:38,416 - INFO - downloader - image #4\thttps://e00-marca.uecdn.es/assets/multimedia/imagenes/2022/09/13/16630884605041.jpg\n",
      "2025-09-06 15:26:38,525 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E1F2A360>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 2\n",
      "2025-09-06 15:26:38,527 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E1F28230>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 1\n",
      "2025-09-06 15:26:38,529 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2023/10/neymar-jr-wallpaper-2.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E1F2A360>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 0\n",
      "2025-09-06 15:26:38,538 - INFO - downloader - image #5\thttps://wallpapers.com/images/hd/neymar-jr-high-contrast-shot-aee4qjdc96ifkdq7.jpg\n",
      "2025-09-06 15:26:40,357 - INFO - downloader - image #6\thttps://inspirationseek.com/wp-content/uploads/2016/02/Neymar_05.jpg\n",
      "2025-09-06 15:26:41,213 - INFO - downloader - image #7\thttps://images.hdqwalls.com/wallpapers/neymar-jr-fifa-world-cup-qatar-03.jpg\n",
      "2025-09-06 15:26:43,362 - INFO - downloader - image #8\thttps://wallpaper.dog/large/5558838.jpg\n",
      "2025-09-06 15:26:43,517 - INFO - downloader - image #9\thttps://wallpapers.com/images/hd/neymar-jr-black-fly-emirates-filis9yufcsodtvu.jpg\n",
      "2025-09-06 15:26:44,919 - INFO - downloader - image #10\thttps://i.pinimg.com/originals/8b/4f/6d/8b4f6d236bc9fb2fae86f12eea04e52a.jpg\n",
      "2025-09-06 15:26:48,783 - INFO - downloader - image #11\thttp://wallpapercave.com/wp/wp1902812.jpg\n",
      "2025-09-06 15:26:49,595 - INFO - downloader - image #12\thttps://i.pinimg.com/originals/9a/c4/a9/9ac4a92ca3395fcfa328970c2c4188e1.jpg\n",
      "2025-09-06 15:26:50,443 - INFO - downloader - image #13\thttps://3.bp.blogspot.com/-WINrU6PXg8g/V4iesZ0YAJI/AAAAAAAAFXw/9SfJ_7dBMoIrgJYb--jfoxAp_Et-0NX7QCLcB/s1600/Neymar%2BJr.%2BHD%2BWallpapers%252CImages%2B%2526%2BPictures%2BFree%2BDownload.jpg\n",
      "2025-09-06 15:26:55,752 - ERROR - downloader - Exception caught when downloading file https://superstarsbio.com/wp-content/uploads/2019/01/Neymar.jpg, error: HTTPSConnectionPool(host='superstarsbio.com', port=443): Read timed out. (read timeout=5), remaining retry times: 2\n",
      "2025-09-06 15:27:00,880 - ERROR - downloader - Exception caught when downloading file https://superstarsbio.com/wp-content/uploads/2019/01/Neymar.jpg, error: HTTPSConnectionPool(host='superstarsbio.com', port=443): Read timed out. (read timeout=5), remaining retry times: 1\n",
      "2025-09-06 15:27:00,979 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr photo&first=20\n",
      "2025-09-06 15:27:03,971 - INFO - downloader - image #14\thttps://superstarsbio.com/wp-content/uploads/2019/01/Neymar.jpg\n",
      "2025-09-06 15:27:04,158 - ERROR - downloader - Response status code 403, file https://images.wallpapersden.com/image/download/neymar-jr_am5oaWWUmZqaraWkpJRobWllrWdpZWU.jpg\n",
      "2025-09-06 15:27:04,897 - INFO - downloader - image #15\thttps://images.lifestyleasia.com/wp-content/uploads/sites/6/2022/11/29105943/neymar-jr-net-worth-brazil-world-cup-football-1350x900.jpg\n",
      "2025-09-06 15:27:05,469 - INFO - downloader - image #16\thttps://r1.ilikewallpaper.net/iphone-x-wallpapers/download/88870/Neymar-Jr-Brazil-iphone-x-wallpaper-ilikewallpaper_com.jpg\n",
      "2025-09-06 15:27:05,570 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E1DC2420>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 2\n",
      "2025-09-06 15:27:05,575 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E080E810>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 1\n",
      "2025-09-06 15:27:05,578 - ERROR - downloader - Exception caught when downloading file https://www.enwallpaper.com/wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg, error: HTTPSConnectionPool(host='www.enwallpaper.com', port=443): Max retries exceeded with url: /wp-content/uploads/2022/03/Neymar-Jr-2018-HD-Mobile-Wallpaper.jpg (Caused by NameResolutionError(\"<urllib3.connection.HTTPSConnection object at 0x00000192E080E2D0>: Failed to resolve 'www.enwallpaper.com' ([Errno 11001] getaddrinfo failed)\")), remaining retry times: 0\n",
      "2025-09-06 15:27:07,548 - INFO - downloader - image #17\thttps://static1.purepeople.com/articles/4/42/22/34/@/6068597-neymar-jr-psg-lors-du-match-de-ligue-1-580x0-2.jpg\n",
      "2025-09-06 15:27:08,300 - INFO - downloader - image #18\thttps://i.pinimg.com/originals/00/ab/22/00ab2280db9c174083b6c5fd13768ed2.jpg\n",
      "2025-09-06 15:27:09,650 - INFO - downloader - image #19\thttp://wallpapercave.com/wp/wp1827730.jpg\n",
      "2025-09-06 15:27:10,173 - INFO - downloader - image #20\thttps://wallpapers.com/images/hd/neymar-jr-brazil-player-8xvtifv6daykiw8u.jpg\n",
      "2025-09-06 15:27:10,716 - INFO - downloader - image #21\thttps://i.pinimg.com/originals/6e/d5/a0/6ed5a08ee4556ba9d068b652316b333f.jpg\n",
      "2025-09-06 15:27:11,219 - INFO - parser - parsing result page https://www.bing.com/images/async?q=Neymar Jr photo&first=40\n",
      "2025-09-06 15:27:13,048 - INFO - downloader - image #22\thttps://cdn.wallpapersafari.com/43/39/218XRQ.jpg\n",
      "2025-09-06 15:27:15,426 - INFO - downloader - image #23\thttps://cdn.vox-cdn.com/thumbor/hM8QAfyJDjWv5hgC8KFRBPZoVpw=/0x0:3456x5184/1200x0/filters:focal(0x0:3456x5184):no_upscale()/cdn.vox-cdn.com/uploads/chorus_asset/file/3735778/GettyImages-451389280.0.0.jpg\n",
      "2025-09-06 15:27:16,194 - INFO - downloader - image #24\thttps://i.eurosport.com/2021/05/08/3128245-64120628-2560-1440.jpg\n",
      "2025-09-06 15:27:16,657 - INFO - downloader - image #25\thttps://i.pinimg.com/originals/44/96/2f/44962fa23eec7ecc02e9d9b661e53b68.jpg\n",
      "2025-09-06 15:27:17,470 - INFO - downloader - image #26\thttps://i.pinimg.com/originals/e2/3f/06/e23f064a32ee2f35a1a114fabfbe9c7c.jpg\n",
      "2025-09-06 15:27:17,905 - INFO - downloader - image #27\thttps://www.gistreel.com/wp-content/uploads/2025/09/PhotoGrid_Plus_1757037392292.jpg\n",
      "2025-09-06 15:27:18,352 - INFO - downloader - image #28\thttps://i.pinimg.com/originals/0a/04/c6/0a04c630d9d2b583dcf513ecb6839907.jpg\n",
      "2025-09-06 15:27:18,440 - INFO - downloader - image #29\thttps://i.pinimg.com/originals/85/5d/7a/855d7a4233a9f76ba836c9afbafd41d3.jpg\n",
      "2025-09-06 15:27:18,938 - INFO - downloader - image #30\thttps://i.pinimg.com/originals/75/c5/09/75c5099341c94a076a8cf47ce47b13cc.jpg\n",
      "2025-09-06 15:27:19,951 - INFO - downloader - image #31\thttps://i.pinimg.com/originals/7e/87/86/7e878687ee4bb91c9214be376c7fd516.jpg\n",
      "2025-09-06 15:27:20,455 - INFO - downloader - image #32\thttps://i.pinimg.com/originals/09/ca/9b/09ca9be1649ac456dcdb08f5937a71ee.jpg\n",
      "2025-09-06 15:27:20,543 - INFO - downloader - image #33\thttps://wallpapers.com/images/hd/digital-art-of-neymar-jr-33bhpka1a9n5khm7.jpg\n",
      "2025-09-06 15:27:20,819 - INFO - downloader - image #34\thttps://i.pinimg.com/originals/f6/45/f0/f645f02e06db1b4652a738126ba1cddb.jpg\n",
      "2025-09-06 15:27:21,271 - INFO - downloader - image #35\thttps://i.pinimg.com/originals/fb/2c/be/fb2cbe1cfd52004a1c70a8c81b4bb639.jpg\n",
      "2025-09-06 15:27:22,737 - INFO - downloader - image #36\thttps://wallpapercave.com/wp/wp7767750.jpg\n",
      "2025-09-06 15:27:22,941 - INFO - parser - no more page urls for thread parser-001 to parse\n",
      "2025-09-06 15:27:22,943 - INFO - parser - thread parser-001 exit\n",
      "2025-09-06 15:27:23,656 - INFO - downloader - image #37\thttps://i.pinimg.com/originals/1e/44/9a/1e449a15f635d1248be1b3933bd07c1f.jpg\n",
      "2025-09-06 15:27:24,126 - INFO - downloader - image #38\thttps://i.pinimg.com/originals/3a/d9/a2/3ad9a2db332fb7eaac9c24d59cbaf6be.jpg\n",
      "2025-09-06 15:27:29,130 - INFO - downloader - no more download task for thread downloader-002\n",
      "2025-09-06 15:27:29,132 - INFO - downloader - thread downloader-002 exit\n",
      "2025-09-06 15:27:50,887 - INFO - downloader - image #39\thttp://getwallpapers.com/wallpaper/full/4/e/6/1102355-beautiful-neymar-jr-wallpaper-2018-hd-2048x2880-lockscreen.jpg\n"
     ]
    }
   ],
   "source": [
    "from icrawler.builtin import GoogleImageCrawler, BingImageCrawler, BaiduImageCrawler\n",
    "from pathlib import Path\n",
    "import hashlib\n",
    "import time\n",
    "import random\n",
    "\n",
    "PROGRESS_FILE = \"progress.txt\"\n",
    "\n",
    "# ------------------------------\n",
    "# Utility functions\n",
    "# ------------------------------\n",
    "def get_image_hash(image_path: Path) -> str | None:\n",
    "    try:\n",
    "        return hashlib.md5(image_path.read_bytes()).hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def load_existing_hashes(folder: Path) -> set[str]:\n",
    "    hashes = set()\n",
    "    for file in folder.glob(\"*.[jp][pn]g\"):\n",
    "        img_hash = get_image_hash(file)\n",
    "        if img_hash:\n",
    "            hashes.add(img_hash)\n",
    "    return hashes\n",
    "\n",
    "def count_recent_unique_images(folder: Path, existing_hashes: set[str], seconds: int = 3600) -> int:\n",
    "    now = time.time()\n",
    "    new_count = 0\n",
    "    for file in folder.glob(\"*.[jp][pn]g\"):\n",
    "        if now - file.stat().st_mtime <= seconds:\n",
    "            img_hash = get_image_hash(file)\n",
    "            if img_hash and img_hash not in existing_hashes:\n",
    "                existing_hashes.add(img_hash)\n",
    "                new_count += 1\n",
    "    return new_count\n",
    "\n",
    "def save_progress(celebrity: str, status: str):\n",
    "    with open(PROGRESS_FILE, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"{celebrity}|{status}\\n\")\n",
    "\n",
    "def load_progress() -> dict[str, str]:\n",
    "    progress = {}\n",
    "    if Path(PROGRESS_FILE).exists():\n",
    "        with open(PROGRESS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                if \"|\" in line:\n",
    "                    celeb, status = line.strip().split(\"|\", 1)\n",
    "                    progress[celeb] = status\n",
    "    return progress\n",
    "\n",
    "# ------------------------------\n",
    "# Core image downloading\n",
    "# ------------------------------\n",
    "def download_images(celebrity: str, max_images: int = 100) -> bool:\n",
    "    folder = Path(\"images\") / celebrity.replace(\" \", \"_\")\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    existing_hashes = load_existing_hashes(folder)\n",
    "    print(f\"[INFO] {celebrity}: Found {len(existing_hashes)} existing images\")\n",
    "\n",
    "    needed = max(0, max_images - len(existing_hashes))\n",
    "    if needed == 0:\n",
    "        print(f\"[INFO] {celebrity}: Already have enough images\")\n",
    "        return True\n",
    "\n",
    "    keywords = [\n",
    "        f\"{celebrity} face\", f\"{celebrity} portrait\", f\"{celebrity} headshot\",\n",
    "        f\"{celebrity} close up\", f\"{celebrity} photo\", f\"{celebrity} still\",\n",
    "        f\"{celebrity} candid\", f\"{celebrity} professional photo\",\n",
    "        f\"{celebrity} movie still\", f\"{celebrity} event photo\"\n",
    "    ]\n",
    "    random.shuffle(keywords)\n",
    "\n",
    "    search_engines = [\n",
    "        (\"Bing\", BingImageCrawler),\n",
    "        (\"Baidu\", BaiduImageCrawler),\n",
    "        (\"Google\", GoogleImageCrawler),\n",
    "    ]\n",
    "\n",
    "    total_downloaded = 0\n",
    "    max_attempts = 3\n",
    "\n",
    "    for attempt in range(1, max_attempts + 1):\n",
    "        if total_downloaded >= needed:\n",
    "            break\n",
    "        print(f\"[INFO] {celebrity}: Attempt {attempt}\")\n",
    "\n",
    "        for engine_name, Engine in search_engines:\n",
    "            if total_downloaded >= needed:\n",
    "                break\n",
    "            print(f\"[INFO] Using {engine_name}\")\n",
    "\n",
    "            for keyword in keywords:\n",
    "                if total_downloaded >= needed:\n",
    "                    break\n",
    "                print(f\"   [SEARCH] {keyword}\")\n",
    "\n",
    "                try:\n",
    "                    crawler = Engine(\n",
    "                        feeder_threads=1,\n",
    "                        parser_threads=1,\n",
    "                        downloader_threads=2,\n",
    "                        storage={\"root_dir\": str(folder)},\n",
    "                    )\n",
    "\n",
    "                    remaining = needed - total_downloaded\n",
    "                    try:\n",
    "                        crawler.crawl(\n",
    "                            keyword=keyword,\n",
    "                            max_num=min(50, remaining * 2),\n",
    "                            min_size=(250, 250),\n",
    "                            file_idx_offset=\"auto\",\n",
    "                        )\n",
    "                    except TypeError as e:\n",
    "                        if \"'NoneType' object is not iterable\" in str(e):\n",
    "                            print(f\"   [WARNING] No results for '{keyword}' on {engine_name}, skipping...\")\n",
    "                            continue\n",
    "                        else:\n",
    "                            raise e\n",
    "\n",
    "                    new_unique = count_recent_unique_images(folder, existing_hashes)\n",
    "                    total_downloaded += new_unique\n",
    "                    print(f\"   [INFO] +{new_unique} unique → {total_downloaded}/{needed}\")\n",
    "\n",
    "                    time.sleep(random.uniform(3, 8))  # polite delay\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"   [ERROR] {keyword} on {engine_name}: {e}\")\n",
    "                    time.sleep(10)\n",
    "                    continue\n",
    "\n",
    "        if total_downloaded < needed:\n",
    "            wait_time = attempt * 2\n",
    "            print(f\"[INFO] Waiting {wait_time}s before retry...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    final_count = len(list(folder.glob(\"*.[jp][pn]g\")))\n",
    "    success = final_count >= max_images * 0.8\n",
    "    print(f\"[{'SUCCESS' if success else 'PARTIAL'}] {celebrity}: {final_count}/{max_images} images\")\n",
    "    return success\n",
    "\n",
    "# ------------------------------\n",
    "# Main script with resume\n",
    "# ------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    celebrities = [\n",
    "        \"Robert Downey Jr\", \"Chris Evans\", \"Scarlett Johansson\", \"Tom Holland\", \"Zendaya\",\n",
    "        \"Emma Watson\", \"Leonardo DiCaprio\", \"Brad Pitt\", \"Angelina Jolie\", \"Jennifer Lawrence\",\n",
    "        \"Taylor Swift\", \"Ariana Grande\", \"Justin Bieber\", \"Selena Gomez\", \"Billie Eilish\",\n",
    "        \"Ed Sheeran\", \"Beyoncé\", \"Rihanna\", \"Drake\", \"Shawn Mendes\",\n",
    "        \"Lionel Messi\", \"Cristiano Ronaldo\", \"Neymar Jr\", \"Kylian Mbappé\", \"Virat Kohli\",\n",
    "        \"Serena Williams\", \"Roger Federer\", \"LeBron James\", \"Michael Jordan\", \"Usain Bolt\",\n",
    "        \"Kim Kardashian\", \"Kylie Jenner\", \"Dwayne Johnson\", \"Kevin Hart\", \"Will Smith\",\n",
    "        \"Priyanka Chopra\", \"Deepika Padukone\", \"Shahrukh Khan\", \"Amitabh Bachchan\", \"Hrithik Roshan\",\n",
    "        \"Barack Obama\", \"Elon Musk\", \"Jeff Bezos\", \"Bill Gates\", \"Mark Zuckerberg\",\n",
    "        \"Oprah Winfrey\", \"Malala Yousafzai\", \"Pope Francis\", \"Jackie Chan\"\n",
    "    ]\n",
    "\n",
    "    progress = load_progress()\n",
    "    successful, failed = [], []\n",
    "\n",
    "    for celeb in celebrities:\n",
    "        if progress.get(celeb) == \"SUCCESS\":\n",
    "            print(f\"[SKIP] {celeb}: Already completed.\")\n",
    "            successful.append(celeb)\n",
    "            # Short wait for skipped celeb\n",
    "            time.sleep(random.uniform(1, 2))\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n{'='*60}\\nDownloading images for: {celeb}\\n{'='*60}\")\n",
    "        try:\n",
    "            if download_images(celeb, max_images=100):\n",
    "                successful.append(celeb)\n",
    "                save_progress(celeb, \"SUCCESS\")\n",
    "            else:\n",
    "                failed.append(celeb)\n",
    "                save_progress(celeb, \"FAILED\")\n",
    "\n",
    "            # Wait for next celeb (slightly longer for fresh downloads)\n",
    "            time.sleep(random.uniform(2, 5))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Skipping {celeb}: {e}\")\n",
    "            failed.append(celeb)\n",
    "            save_progress(celeb, \"FAILED\")\n",
    "            time.sleep(60)  # long backoff on error\n",
    "\n",
    "    # Summary\n",
    "    print(f\"\\n{'='*60}\\nDOWNLOAD SUMMARY\\n{'='*60}\")\n",
    "    print(f\"Successful: {len(successful)}/{len(celebrities)}\")\n",
    "    print(f\"Failed: {len(failed)}/{len(celebrities)}\")\n",
    "    if failed:\n",
    "        print(\"Failed downloads:\")\n",
    "        for f in failed:\n",
    "            print(f\"  - {f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b65b9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
