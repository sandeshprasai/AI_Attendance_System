{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67aa31-c0d3-4994-a98e-d477b848e3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TF version:\", tf.__version__)\n",
    "print(\"Listing GPUs...\")\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Done\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc58b17-f10f-4853-b60c-3ee36931277f",
   "metadata": {},
   "outputs": [],
   "source": [
    "    import tensorflow as tf\n",
    "    import pandas as pd\n",
    "    import os\n",
    "    import json\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from tensorflow.keras.models import Model, load_model\n",
    "    from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "    from tensorflow.keras.regularizers import l2\n",
    "    \n",
    "    # -----------------------------\n",
    "    # GPU Setup\n",
    "    # -----------------------------\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "            tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "            device = '/GPU:0'\n",
    "            print(f\"Using GPU: {gpus[0]}\")\n",
    "        except:\n",
    "            device = '/CPU:0'\n",
    "    else:\n",
    "        device = '/CPU:0'\n",
    "        print(\"Using CPU\")\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Dataset Path (Single Folder)\n",
    "    # -----------------------------\n",
    "    dataset_dir = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\FullProcessedAgumented\"\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Create DataFrame of Images\n",
    "    # -----------------------------\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    \n",
    "    for label in os.listdir(dataset_dir):\n",
    "        class_dir = os.path.join(dataset_dir, label)\n",
    "        if os.path.isdir(class_dir):\n",
    "            for file in os.listdir(class_dir):\n",
    "                filepaths.append(os.path.join(class_dir, file))\n",
    "                labels.append(label)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'filepath': filepaths,\n",
    "        'label': labels\n",
    "    })\n",
    "    \n",
    "    print(\"Total images found:\", len(df))\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Split dataset (sklearn)\n",
    "    # -----------------------------\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "    \n",
    "    print(\"Train:\", len(train_df), \" Val:\", len(val_df), \" Test:\", len(test_df))\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Generators\n",
    "    # -----------------------------\n",
    "    img_size = (112,112)\n",
    "    batch_size = 16\n",
    "    \n",
    "    datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        train_df, x_col='filepath', y_col='label',\n",
    "        target_size=img_size, class_mode='categorical', batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    val_gen = datagen.flow_from_dataframe(\n",
    "        val_df, x_col='filepath', y_col='label',\n",
    "        target_size=img_size, class_mode='categorical', batch_size=batch_size\n",
    "    )\n",
    "    \n",
    "    test_gen = datagen.flow_from_dataframe(\n",
    "        test_df, x_col='filepath', y_col='label',\n",
    "        target_size=img_size, class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    "    )\n",
    "    \n",
    "    num_classes = len(train_gen.class_indices)\n",
    "    print(\"Number of classes:\", num_classes)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Model\n",
    "    # -----------------------------\n",
    "    checkpoint_path = \"checkpoints/best_model.keras\"\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    with tf.device(device):\n",
    "        if os.path.exists(checkpoint_path):\n",
    "            print(\"Loading checkpoint model…\")\n",
    "            model = load_model(checkpoint_path)\n",
    "        else:\n",
    "            inputs = Input(shape=(112,112, 3))\n",
    "            \n",
    "            x = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(inputs)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = MaxPooling2D(2,2)(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "    \n",
    "            x = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = MaxPooling2D(2,2)(x)\n",
    "            x = Dropout(0.3)(x)\n",
    "    \n",
    "            x = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = MaxPooling2D(2,2)(x)\n",
    "            x = Dropout(0.4)(x)\n",
    "    \n",
    "            x = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = BatchNormalization()(x)\n",
    "            x = MaxPooling2D(2,2)(x)\n",
    "            x = Dropout(0.4)(x)\n",
    "    \n",
    "            x = GlobalAveragePooling2D()(x)\n",
    "            x = Dense(512, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = Dropout(0.6)(x)\n",
    "            x = Dense(256, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "            x = Dropout(0.6)(x)\n",
    "    \n",
    "            outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "            model = Model(inputs, outputs)\n",
    "    \n",
    "            model.compile(\n",
    "                optimizer=Adam(0.0005),\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy']\n",
    "            )\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Callbacks\n",
    "    # -----------------------------\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.3)\n",
    "    checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss')\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Train\n",
    "    # -----------------------------\n",
    "    history = model.fit(train_gen, validation_data=val_gen, epochs=50,\n",
    "                        callbacks=[early_stop, reduce_lr, checkpoint])\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Test Evaluation\n",
    "    # -----------------------------\n",
    "    test_loss, test_acc = model.evaluate(test_gen)\n",
    "    print(\"Test accuracy:\", test_acc)\n",
    "    \n",
    "    # -----------------------------\n",
    "    # Save final model & labels\n",
    "    # -----------------------------\n",
    "    model.save(\"face_recognition_attendance_final.keras\")\n",
    "    model.save(\"face_recognition_attendance_final.h5\")\n",
    "    \n",
    "    with open(\"class_labels.json\", \"w\") as f:\n",
    "        json.dump(train_gen.class_indices, f)\n",
    "    \n",
    "    print(\"Model + labels saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08d41262-fbf5-4460-a0c0-e8f11b15afee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    precision_recall_curve,\n",
    "    roc_curve,\n",
    "    auc,\n",
    "    roc_auc_score\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef3996c-0b13-414d-96af-5aa20afbaea7",
   "metadata": {},
   "source": [
    "## Get Predictions & True Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1beafde4-b5c9-40af-9d6c-e3436b76944e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 3s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "y_prob = model.predict(test_gen)\n",
    "\n",
    "# True labels (integer encoded)\n",
    "y_true = test_gen.classes\n",
    "\n",
    "# Predicted class labels\n",
    "y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2db5bf-d540-47f9-8f0f-866ac90add6f",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2772941a-76c6-471c-986c-4800b8915d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names\n",
    ")\n",
    "\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "# ✅ SAVE IMAGE\n",
    "plt.savefig(\n",
    "    \"confusion_matrix.png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2642b8e-1783-4610-8ab7-199b1725d114",
   "metadata": {},
   "source": [
    "## Classification Report (Precision, Recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aafbff1-5c7a-43ff-9749-cb0dc7a6e214",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=class_names\n",
    "))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428c1f0-b880-46a0-980e-83edde22a2ae",
   "metadata": {},
   "source": [
    "## Precision–Recall Curve (Micro-Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f475a5-0d2e-429b-94e8-7736aaa4b3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(\n",
    "    y_true_bin.ravel(),\n",
    "    y_prob.ravel()\n",
    ")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.title(\"Precision–Recall Curve (Micro-Average)\")\n",
    "plt.grid()\n",
    "plt.savefig(\n",
    "    \"Precison_Recall_Curve(Micro-Average).png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae9314f-98f6-444e-adff-b5685933642d",
   "metadata": {},
   "source": [
    "## F1-Score vs Threshold Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae57d2-13d1-4660-99d9-245e889f4eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores = 2 * (precision * recall) / (precision + recall + 1e-8)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(thresholds, f1_scores[:-1])\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"F1 Score\")\n",
    "plt.title(\"F1 Score vs Threshold\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74989a28-6bda-4a3f-8741-b2cba2efdb4f",
   "metadata": {},
   "source": [
    "## Recall vs Threshold Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a6392-057f-41db-a87f-fdfcbe7fbef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(thresholds, recall[:-1])\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.title(\"Recall vs Threshold\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cec2982-0d19-4f07-a4bd-8cb445312170",
   "metadata": {},
   "source": [
    "## ROC Curve + AUC (Micro-Average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025aef30-8c0a-4d92-9178-046732ea7cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(\n",
    "    y_true_bin.ravel(),\n",
    "    y_prob.ravel()\n",
    ")\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"AUC = {roc_auc:.4f}\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve (Micro-Average)\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(\n",
    "    \"ROC_Curve(Micro-Average).png\",\n",
    "    dpi=300,\n",
    "    bbox_inches=\"tight\"\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27a12f-bc43-4d78-925d-bf0d78c0d146",
   "metadata": {},
   "source": [
    "## AUC Score (Numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3893391b-f747-45b1-8d30-e658046c8490",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(\n",
    "    y_true_bin,\n",
    "    y_prob,\n",
    "    average=\"micro\"\n",
    ")\n",
    "\n",
    "print(\"ROC AUC Score (Micro-Average):\", auc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa6f49-562d-46f0-b0d2-7921f52dfb26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
