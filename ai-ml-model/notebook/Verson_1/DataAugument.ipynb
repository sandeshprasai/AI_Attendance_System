{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1e71c-80cf-4097-aa10-f3b4f45aa303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facial Recognition Dataset Balancer\n",
      "==================================================\n",
      "Using 2 workers for processing\n",
      "\n",
      "============================================================\n",
      "Starting dataset balancing\n",
      "Input: D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\raw\n",
      "Output: D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\FullProcessedAgumented\n",
      "Target: 500 images per class at (112, 112)\n",
      "============================================================\n",
      "\n",
      "Found 540 classes\n",
      "Processing 540 classes (skipping 0 already processed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: n000270 ✓: 100%|█████████████████████████████████████| 540/540 [1:03:42<00:00,  7.08s/it, Classes: 540/540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING STATISTICS\n",
      "============================================================\n",
      "Total classes processed: 540\n",
      "Total images augmented: 6,634\n",
      "Failed images: 0\n",
      "Total time: 3825.2 seconds\n",
      "Average time per class: 7.1s\n",
      "Images augmented per second: 1.7\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "VERIFYING DATASET\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verifying classes: 100%|███████████████████████████████████████████| 540/540 [00:04<00:00, 116.99it/s, Passed: 540/540]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUMMARY:\n",
      "  Classes: 540\n",
      "  Classes with ≥500 images: 540/540\n",
      "  Total images: 270,000\n",
      "  Average images per class: 500.0\n",
      "\n",
      "✓ All classes have at least 500 images!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "from glob import glob\n",
    "import multiprocessing as mp\n",
    "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "class FacialDataBalancer:\n",
    "    def __init__(self, target_count=300, target_size=(112, 112), \n",
    "                 max_workers=None, use_multiprocessing=True):\n",
    "        self.target_count = target_count\n",
    "        self.target_size = target_size\n",
    "        self.use_multiprocessing = use_multiprocessing\n",
    "        \n",
    "        # Set max workers (use CPU cores - 2 for stability)\n",
    "        if max_workers is None:\n",
    "            self.max_workers = max(1, mp.cpu_count() - 2)\n",
    "        else:\n",
    "            self.max_workers = max_workers\n",
    "        \n",
    "        print(f\"Using {self.max_workers} workers for processing\")\n",
    "        \n",
    "        # Define augmentation pipelines\n",
    "        self.setup_augmentation_pipelines()\n",
    "        \n",
    "        # Statistics\n",
    "        self.stats = {\n",
    "            'total_processed': 0,\n",
    "            'total_augmented': 0,\n",
    "            'failed_images': 0,\n",
    "            'start_time': time.time()\n",
    "        }\n",
    "        \n",
    "        # For single progress bar\n",
    "        self.main_progress_bar = None\n",
    "    \n",
    "    def setup_augmentation_pipelines(self):\n",
    "        \"\"\"Setup different augmentation pipelines based on dataset size\"\"\"\n",
    "        # Light augmentations (for nearly sufficient datasets)\n",
    "        self.light_aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.03,\n",
    "                scale_limit=0.03,\n",
    "                rotate_limit=3,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.1,\n",
    "                contrast_limit=0.1,\n",
    "                p=0.2\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # Moderate augmentations (for medium-sized datasets)\n",
    "        self.moderate_aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.5),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.07,\n",
    "                scale_limit=0.07,\n",
    "                rotate_limit=7,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.15,\n",
    "                contrast_limit=0.15,\n",
    "                p=0.4\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=5,\n",
    "                sat_shift_limit=10,\n",
    "                val_shift_limit=10,\n",
    "                p=0.3\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(5.0, 15.0), p=0.2)\n",
    "        ])\n",
    "        \n",
    "        # Aggressive augmentations (for small datasets)\n",
    "        self.aggressive_aug = A.Compose([\n",
    "            A.HorizontalFlip(p=0.7),\n",
    "            A.ShiftScaleRotate(\n",
    "                shift_limit=0.1,\n",
    "                scale_limit=0.1,\n",
    "                rotate_limit=10,\n",
    "                p=0.7\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(\n",
    "                brightness_limit=0.2,\n",
    "                contrast_limit=0.2,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.HueSaturationValue(\n",
    "                hue_shift_limit=10,\n",
    "                sat_shift_limit=20,\n",
    "                val_shift_limit=20,\n",
    "                p=0.5\n",
    "            ),\n",
    "            A.GaussNoise(var_limit=(10.0, 30.0), p=0.3),\n",
    "            A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "            A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "            A.CoarseDropout(\n",
    "                max_holes=2,\n",
    "                max_height=8,\n",
    "                max_width=8,\n",
    "                min_holes=1,\n",
    "                min_height=4,\n",
    "                min_width=4,\n",
    "                fill_value=0,\n",
    "                p=0.1\n",
    "            )\n",
    "        ])\n",
    "    \n",
    "    def balance_dataset(self, dataset_path, output_path, checkpoint_interval=5):\n",
    "        \"\"\"\n",
    "        Main function to balance the dataset with a single progress bar\n",
    "        \"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Starting dataset balancing\")\n",
    "        print(f\"Input: {dataset_path}\")\n",
    "        print(f\"Output: {output_path}\")\n",
    "        print(f\"Target: {self.target_count} images per class at {self.target_size}\")\n",
    "        print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        # Get class distribution\n",
    "        class_distribution = self.get_class_distribution(dataset_path)\n",
    "        total_classes = len(class_distribution)\n",
    "        \n",
    "        print(f\"Found {total_classes} classes\")\n",
    "        \n",
    "        # Process classes with checkpointing\n",
    "        processed_classes = self.load_checkpoint(output_path)\n",
    "        \n",
    "        # Calculate number of classes to process\n",
    "        classes_to_process = [c for c in class_distribution.keys() if c not in processed_classes]\n",
    "        \n",
    "        if not classes_to_process:\n",
    "            print(\"\\nAll classes already processed!\")\n",
    "            return\n",
    "        \n",
    "        print(f\"Processing {len(classes_to_process)} classes (skipping {len(processed_classes)} already processed)\")\n",
    "        \n",
    "        # Create single main progress bar\n",
    "        self.main_progress_bar = tqdm(\n",
    "            total=len(classes_to_process),\n",
    "            desc=\"Overall Progress\",\n",
    "            position=0,\n",
    "            leave=True,\n",
    "            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]'\n",
    "        )\n",
    "        \n",
    "        # Add initial info to progress bar\n",
    "        self.main_progress_bar.set_postfix_str(f\"Classes: 0/{len(classes_to_process)}\")\n",
    "        \n",
    "        # Process each class\n",
    "        for idx, class_name in enumerate(classes_to_process, 1):\n",
    "            image_paths = class_distribution[class_name]\n",
    "            \n",
    "            # Update progress bar description\n",
    "            self.main_progress_bar.set_description(f\"Processing: {class_name}\")\n",
    "            \n",
    "            current_count = len(image_paths)\n",
    "            \n",
    "            # Process the class\n",
    "            if current_count >= self.target_count:\n",
    "                self.process_sufficient_class_simple(image_paths, class_name, output_path)\n",
    "            else:\n",
    "                self.augment_class_simple(image_paths, class_name, current_count, output_path)\n",
    "            \n",
    "            # Update checkpoint\n",
    "            processed_classes.add(class_name)\n",
    "            if idx % checkpoint_interval == 0:\n",
    "                self.save_checkpoint(output_path, processed_classes)\n",
    "            \n",
    "            # Update statistics and progress bar\n",
    "            self.stats['total_processed'] += 1\n",
    "            self.main_progress_bar.update(1)\n",
    "            self.main_progress_bar.set_postfix_str(f\"Classes: {idx}/{len(classes_to_process)}\")\n",
    "        \n",
    "        # Close main progress bar\n",
    "        self.main_progress_bar.close()\n",
    "        \n",
    "        # Save final checkpoint\n",
    "        self.save_checkpoint(output_path, processed_classes)\n",
    "        \n",
    "        # Print final statistics\n",
    "        self.print_statistics()\n",
    "    \n",
    "    def process_sufficient_class_simple(self, image_paths, class_name, output_path):\n",
    "        \"\"\"Simple processing for classes with enough images\"\"\"\n",
    "        output_class_dir = Path(output_path) / class_name\n",
    "        output_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Sample target_count images if there are more\n",
    "        if len(image_paths) > self.target_count:\n",
    "            image_paths = random.sample(image_paths, self.target_count)\n",
    "        \n",
    "        count = 0\n",
    "        for idx, img_path in enumerate(image_paths):\n",
    "            img = self.load_and_resize(img_path)\n",
    "            if img is not None:\n",
    "                output_path_img = output_class_dir / f\"{class_name}_{idx:04d}.jpg\"\n",
    "                cv2.imwrite(str(output_path_img), img[:, :, ::-1])\n",
    "                count += 1\n",
    "        \n",
    "        # Update progress bar with brief info\n",
    "        if self.main_progress_bar:\n",
    "            old_desc = self.main_progress_bar.desc\n",
    "            self.main_progress_bar.set_description(f\"{old_desc.split(':')[0]}: {class_name} ✓\")\n",
    "    \n",
    "    def augment_class_simple(self, image_paths, class_name, current_count, output_path):\n",
    "        \"\"\"Simple augmentation without individual progress bars\"\"\"\n",
    "        output_class_dir = Path(output_path) / class_name\n",
    "        output_class_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load and resize all valid images\n",
    "        valid_images = []\n",
    "        for img_path in image_paths:\n",
    "            img = self.load_and_resize(img_path)\n",
    "            if img is not None:\n",
    "                valid_images.append(img)\n",
    "            else:\n",
    "                self.stats['failed_images'] += 1\n",
    "        \n",
    "        if not valid_images:\n",
    "            if self.main_progress_bar:\n",
    "                old_desc = self.main_progress_bar.desc\n",
    "                self.main_progress_bar.set_description(f\"{old_desc.split(':')[0]}: {class_name} ✗ (no valid images)\")\n",
    "            return\n",
    "        \n",
    "        current_count = len(valid_images)\n",
    "        \n",
    "        # Save original images\n",
    "        for i, img in enumerate(valid_images):\n",
    "            output_path_img = output_class_dir / f\"{class_name}_orig_{i:04d}.jpg\"\n",
    "            cv2.imwrite(str(output_path_img), img[:, :, ::-1])\n",
    "        \n",
    "        # Determine augmentation strategy\n",
    "        needed_images = self.target_count - current_count\n",
    "        \n",
    "        if current_count < 50:\n",
    "            augmentations_per_image = min(20, max(5, needed_images // current_count + 1))\n",
    "            augmentation_pipeline = self.aggressive_aug\n",
    "        elif current_count < 200:\n",
    "            augmentations_per_image = min(10, max(3, needed_images // current_count + 1))\n",
    "            augmentation_pipeline = self.moderate_aug\n",
    "        else:\n",
    "            augmentations_per_image = min(5, max(1, needed_images // current_count + 1))\n",
    "            augmentation_pipeline = self.light_aug\n",
    "        \n",
    "        # Generate augmented images\n",
    "        augmented_count = 0\n",
    "        total_to_generate = needed_images\n",
    "        \n",
    "        while augmented_count < total_to_generate:\n",
    "            for img in valid_images:\n",
    "                if augmented_count >= total_to_generate:\n",
    "                    break\n",
    "                \n",
    "                # Generate multiple augmentations per image\n",
    "                for _ in range(augmentations_per_image):\n",
    "                    if augmented_count >= total_to_generate:\n",
    "                        break\n",
    "                    \n",
    "                    try:\n",
    "                        # Apply augmentation\n",
    "                        augmented = augmentation_pipeline(image=img)['image']\n",
    "                        \n",
    "                        # Save augmented image\n",
    "                        output_path_aug = output_class_dir / f\"{class_name}_aug_{augmented_count:04d}.jpg\"\n",
    "                        cv2.imwrite(str(output_path_aug), augmented[:, :, ::-1])\n",
    "                        \n",
    "                        augmented_count += 1\n",
    "                        \n",
    "                    except Exception:\n",
    "                        continue\n",
    "            \n",
    "            # If we still need more images, shuffle and continue\n",
    "            if augmented_count < total_to_generate:\n",
    "                random.shuffle(valid_images)\n",
    "        \n",
    "        # Update statistics\n",
    "        self.stats['total_augmented'] += augmented_count\n",
    "        \n",
    "        # Update progress bar with brief info\n",
    "        if self.main_progress_bar:\n",
    "            old_desc = self.main_progress_bar.desc\n",
    "            self.main_progress_bar.set_description(f\"{old_desc.split(':')[0]}: {class_name} ✓ (+{augmented_count})\")\n",
    "    \n",
    "    def get_class_distribution(self, dataset_path):\n",
    "        \"\"\"Get all images per class efficiently\"\"\"\n",
    "        dataset_path = Path(dataset_path)\n",
    "        distribution = {}\n",
    "        \n",
    "        # Get all class directories\n",
    "        class_dirs = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
    "        \n",
    "        for class_dir in class_dirs:\n",
    "            class_name = class_dir.name\n",
    "            # Use glob with common image extensions\n",
    "            image_patterns = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']\n",
    "            image_paths = []\n",
    "            for pattern in image_patterns:\n",
    "                image_paths.extend(list(class_dir.glob(pattern)))\n",
    "            \n",
    "            # Convert Path objects to strings\n",
    "            image_paths = [str(p) for p in image_paths]\n",
    "            \n",
    "            if image_paths:  # Only include classes with images\n",
    "                distribution[class_name] = image_paths\n",
    "        \n",
    "        # Sort by number of images (ascending)\n",
    "        distribution = dict(sorted(distribution.items(), key=lambda x: len(x[1])))\n",
    "        return distribution\n",
    "    \n",
    "    def load_and_resize(self, image_path):\n",
    "        \"\"\"\n",
    "        Fast and efficient image loading and resizing\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Read image\n",
    "            img = cv2.imread(image_path)\n",
    "            if img is None:\n",
    "                # Try alternative reading for problematic images\n",
    "                try:\n",
    "                    with open(image_path, 'rb') as f:\n",
    "                        img_array = np.frombuffer(f.read(), np.uint8)\n",
    "                        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "                except:\n",
    "                    return None\n",
    "            \n",
    "            if img is None:\n",
    "                return None\n",
    "            \n",
    "            # Convert to RGB\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            h, w = img.shape[:2]\n",
    "            \n",
    "            # Handle different size cases\n",
    "            if h == self.target_size[0] and w == self.target_size[1]:\n",
    "                return img\n",
    "            elif h < self.target_size[0] or w < self.target_size[1]:\n",
    "                return self.quick_resize_small(img)\n",
    "            else:\n",
    "                return self.quick_resize_large(img)\n",
    "                \n",
    "        except Exception as e:\n",
    "            return None\n",
    "    \n",
    "    def quick_resize_small(self, img):\n",
    "        \"\"\"Quick resize for small images\"\"\"\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Simple padding approach for speed\n",
    "        if h < self.target_size[0] or w < self.target_size[1]:\n",
    "            # Calculate padding\n",
    "            pad_h = max(0, self.target_size[0] - h)\n",
    "            pad_w = max(0, self.target_size[1] - w)\n",
    "            \n",
    "            # Apply padding\n",
    "            img = cv2.copyMakeBorder(\n",
    "                img,\n",
    "                pad_h//2, pad_h - pad_h//2,\n",
    "                pad_w//2, pad_w - pad_w//2,\n",
    "                cv2.BORDER_REFLECT101\n",
    "            )\n",
    "        \n",
    "        # Final resize if needed\n",
    "        if img.shape[0] != self.target_size[0] or img.shape[1] != self.target_size[1]:\n",
    "            img = cv2.resize(img, self.target_size, interpolation=cv2.INTER_LINEAR)\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def quick_resize_large(self, img):\n",
    "        \"\"\"Quick resize for large images\"\"\"\n",
    "        # Simple center crop and resize for speed\n",
    "        h, w = img.shape[:2]\n",
    "        \n",
    "        # Calculate scale for center crop\n",
    "        scale = max(self.target_size[0] / h, self.target_size[1] / w)\n",
    "        \n",
    "        # Resize\n",
    "        img = cv2.resize(img, None, fx=scale, fy=scale, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        # Center crop\n",
    "        h_new, w_new = img.shape[:2]\n",
    "        y = (h_new - self.target_size[0]) // 2\n",
    "        x = (w_new - self.target_size[1]) // 2\n",
    "        \n",
    "        img = img[y:y+self.target_size[0], x:x+self.target_size[1]]\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def load_checkpoint(self, output_path):\n",
    "        \"\"\"Load processed classes from checkpoint\"\"\"\n",
    "        checkpoint_file = Path(output_path) / 'checkpoint.pkl'\n",
    "        if checkpoint_file.exists():\n",
    "            try:\n",
    "                with open(checkpoint_file, 'rb') as f:\n",
    "                    processed_classes = pickle.load(f)\n",
    "                print(f\"Loaded checkpoint with {len(processed_classes)} processed classes\")\n",
    "                return set(processed_classes)\n",
    "            except:\n",
    "                print(\"Could not load checkpoint, starting fresh\")\n",
    "        return set()\n",
    "    \n",
    "    def save_checkpoint(self, output_path, processed_classes):\n",
    "        \"\"\"Save checkpoint of processed classes\"\"\"\n",
    "        checkpoint_file = Path(output_path) / 'checkpoint.pkl'\n",
    "        try:\n",
    "            with open(checkpoint_file, 'wb') as f:\n",
    "                pickle.dump(list(processed_classes), f)\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    def print_statistics(self):\n",
    "        \"\"\"Print processing statistics\"\"\"\n",
    "        total_time = time.time() - self.stats['start_time']\n",
    "        \n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(\"PROCESSING STATISTICS\")\n",
    "        print(f\"{'='*60}\")\n",
    "        print(f\"Total classes processed: {self.stats['total_processed']}\")\n",
    "        print(f\"Total images augmented: {self.stats['total_augmented']:,}\")\n",
    "        print(f\"Failed images: {self.stats['failed_images']}\")\n",
    "        print(f\"Total time: {total_time:.1f} seconds\")\n",
    "        \n",
    "        if self.stats['total_processed'] > 0:\n",
    "            print(f\"Average time per class: {total_time/self.stats['total_processed']:.1f}s\")\n",
    "            print(f\"Images augmented per second: {self.stats['total_augmented']/total_time:.1f}\")\n",
    "        \n",
    "        print(f\"{'='*60}\")\n",
    "\n",
    "\n",
    "# ============ VERIFICATION FUNCTION ============\n",
    "\n",
    "def verify_dataset(dataset_path, target_count, target_size, sample_size=5):\n",
    "    \"\"\"Quick verification of the dataset with a single progress bar\"\"\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"VERIFYING DATASET\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    all_classes = [d for d in dataset_path.iterdir() if d.is_dir()]\n",
    "    total_images = 0\n",
    "    passed_classes = 0\n",
    "    \n",
    "    # Single progress bar for verification\n",
    "    with tqdm(total=len(all_classes), desc=\"Verifying classes\", position=0, leave=True) as pbar:\n",
    "        for class_dir in all_classes:\n",
    "            class_name = class_dir.name\n",
    "            \n",
    "            # Count images\n",
    "            image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "            image_count = len(image_files)\n",
    "            \n",
    "            if image_count >= target_count:\n",
    "                passed_classes += 1\n",
    "            \n",
    "            total_images += image_count\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.update(1)\n",
    "            pbar.set_postfix_str(f\"Passed: {passed_classes}/{len(all_classes)}\")\n",
    "    \n",
    "    print(f\"\\nSUMMARY:\")\n",
    "    print(f\"  Classes: {len(all_classes)}\")\n",
    "    print(f\"  Classes with ≥{target_count} images: {passed_classes}/{len(all_classes)}\")\n",
    "    print(f\"  Total images: {total_images:,}\")\n",
    "    print(f\"  Average images per class: {total_images/len(all_classes):.1f}\")\n",
    "    \n",
    "    if passed_classes == len(all_classes):\n",
    "        print(f\"\\n✓ All classes have at least {target_count} images!\")\n",
    "    else:\n",
    "        print(f\"\\n✗ {len(all_classes) - passed_classes} classes are below target count\")\n",
    "    \n",
    "    return passed_classes == len(all_classes)\n",
    "\n",
    "\n",
    "# ============ MAIN EXECUTION ============\n",
    "\n",
    "def main():\n",
    "    # Configuration - CHANGE THESE PATHS\n",
    "    INPUT_PATH = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\raw\"\n",
    "    OUTPUT_PATH = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\FullProcessedAgumented\"\n",
    "    TARGET_SIZE = (112, 112)\n",
    "    TARGET_COUNT = 500\n",
    "    \n",
    "    print(\"Facial Recognition Dataset Balancer\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Initialize balancer\n",
    "    balancer = FacialDataBalancer(\n",
    "        target_count=TARGET_COUNT,\n",
    "        target_size=TARGET_SIZE,\n",
    "        use_multiprocessing=False,  # Set to False to avoid multiprocessing issues\n",
    "        max_workers=2  # Use fewer workers for stability\n",
    "    )\n",
    "    \n",
    "    # Create output directory\n",
    "    Path(OUTPUT_PATH).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Start balancing\n",
    "    try:\n",
    "        balancer.balance_dataset(INPUT_PATH, OUTPUT_PATH)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\nProcess interrupted by user. Checkpoint saved.\")\n",
    "        print(f\"Progress saved to: {Path(OUTPUT_PATH) / 'checkpoint.pkl'}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"\\nError during processing: {e}\")\n",
    "        return\n",
    "    \n",
    "    # Verify results\n",
    "    verify_dataset(OUTPUT_PATH, TARGET_COUNT, TARGET_SIZE)\n",
    "\n",
    "\n",
    "# ============ ALTERNATIVE VERSION WITH STATUS UPDATES ============\n",
    "\n",
    "class FacialDataBalancerSimple:\n",
    "    \"\"\"Even simpler version with just one progress bar\"\"\"\n",
    "    def __init__(self, target_count=500, target_size=(112, 112)):\n",
    "        self.target_count = target_count\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        # Simple augmentation pipeline\n",
    "        self.augmentation = A.Compose([\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=5, p=0.3),\n",
    "            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0.1, p=0.2),\n",
    "        ])\n",
    "    \n",
    "    def balance_simple(self, input_path, output_path):\n",
    "        \"\"\"Simple balancing with single progress bar\"\"\"\n",
    "        import_path = Path(input_path)\n",
    "        output_path = Path(output_path)\n",
    "        \n",
    "        # Get all classes\n",
    "        classes = [d for d in import_path.iterdir() if d.is_dir()]\n",
    "        \n",
    "        print(f\"Processing {len(classes)} classes...\")\n",
    "        \n",
    "        # Single progress bar for all classes\n",
    "        with tqdm(total=len(classes), desc=\"Processing classes\", bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]') as pbar:\n",
    "            for class_dir in classes:\n",
    "                class_name = class_dir.name\n",
    "                \n",
    "                # Update progress bar with current class name\n",
    "                pbar.set_description(f\"Processing: {class_name[:20]:20s}\")\n",
    "                \n",
    "                # Process the class\n",
    "                self._process_class_simple(class_dir, class_name, output_path)\n",
    "                \n",
    "                pbar.update(1)\n",
    "        \n",
    "        print(\"\\nProcessing complete!\")\n",
    "    \n",
    "    def _process_class_simple(self, class_dir, class_name, output_path):\n",
    "        \"\"\"Process a single class\"\"\"\n",
    "        output_dir = output_path / class_name\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Get all images\n",
    "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.jpeg')) + list(class_dir.glob('*.png'))\n",
    "        \n",
    "        if not images:\n",
    "            return\n",
    "        \n",
    "        # Process existing images\n",
    "        for i, img_path in enumerate(images[:min(len(images), self.target_count)]):\n",
    "            try:\n",
    "                img = cv2.imread(str(img_path))\n",
    "                if img is not None:\n",
    "                    img = cv2.resize(img, self.target_size)\n",
    "                    output_file = output_dir / f\"{class_name}_{i:04d}.jpg\"\n",
    "                    cv2.imwrite(str(output_file), img)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Augment if needed\n",
    "        if len(images) < self.target_count:\n",
    "            needed = self.target_count - len(images)\n",
    "            # Simple augmentation from first image\n",
    "            if images:\n",
    "                base_img = cv2.imread(str(images[0]))\n",
    "                if base_img is not None:\n",
    "                    base_img = cv2.resize(base_img, self.target_size)\n",
    "                    for i in range(needed):\n",
    "                        try:\n",
    "                            augmented = self.augmentation(image=base_img)['image']\n",
    "                            output_file = output_dir / f\"{class_name}_aug_{i:04d}.jpg\"\n",
    "                            cv2.imwrite(str(output_file), augmented)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "\n",
    "def run_simple():\n",
    "    \"\"\"Run the simple version\"\"\"\n",
    "    input_path = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\raw\"\n",
    "    output_path = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\ai-ml-model\\DataSets\\ProcessedSimple\"\n",
    "    \n",
    "    balancer = FacialDataBalancerSimple(target_count=500, target_size=(112, 112))\n",
    "    balancer.balance_simple(input_path, output_path)\n",
    "    \n",
    "    print(f\"\\nDataset saved to: {output_path}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the main version (with single progress bar)\n",
    "    main()\n",
    "    \n",
    "    # Or run the simple version\n",
    "    # run_simple()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400024e2-9604-4070-8a55-8968007c5c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (FinalProjEnv)",
   "language": "python",
   "name": "finalprojenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
