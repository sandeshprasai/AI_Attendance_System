{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba4aa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53845294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def get_ipcam_frame(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=2)\n",
    "        if response.status_code != 200:\n",
    "            return None\n",
    "\n",
    "        img_array = np.frombuffer(response.content, np.uint8)\n",
    "        if img_array.size == 0:\n",
    "            return None\n",
    "\n",
    "        frame = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        return frame\n",
    "\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f773ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "PRED_HISTORY = 7\n",
    "conf_buffer = deque(maxlen=PRED_HISTORY)\n",
    "class_buffer = deque(maxlen=PRED_HISTORY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a4cc33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Camera open failed\n",
      "Press 'q' to quit\n",
      "Frame read failed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[tcp @ 0x24e87d00] Connection to tcp://192.168.1.30:4747 failed: Connection timed out\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from collections import deque\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "MODEL_PATH = \"/home/sandeshprasai/Final_Semester_Project/AI_Attendance_System/ai-ml-model/src/models/best_face_model.keras\"\n",
    "LABEL_PATH = \"/home/sandeshprasai/Final_Semester_Project/AI_Attendance_System/ai-ml-model/src/models/class_labels.json\"\n",
    "\n",
    "IP_CAM_STREAM = \"http://192.168.1.30:4747/video\"\n",
    "\n",
    "IMG_SIZE = 112\n",
    "CONF_THRESHOLD = 0.70\n",
    "\n",
    "FRAME_WIDTH = 640\n",
    "FRAME_HEIGHT = 480\n",
    "TARGET_FPS = 10\n",
    "FRAME_SKIP = 2\n",
    "\n",
    "ROTATE_FRAME = True\n",
    "ROTATE_MODE = cv2.ROTATE_90_COUNTERCLOCKWISE  # Adjust if needed\n",
    "\n",
    "# Temporal smoothing config\n",
    "PRED_HISTORY = 7\n",
    "MIN_STABLE_COUNT = 4\n",
    "\n",
    "# ===============================\n",
    "# LOAD CLASS LABELS\n",
    "# ===============================\n",
    "with open(LABEL_PATH, \"r\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "if all(k.isdigit() for k in labels.keys()):\n",
    "    class_names = {int(k): v for k, v in labels.items()}\n",
    "else:\n",
    "    class_names = {v: k for k, v in labels.items()}\n",
    "\n",
    "# ===============================\n",
    "# LOAD MODEL\n",
    "# ===============================\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# ===============================\n",
    "# FACE DETECTOR\n",
    "# ===============================\n",
    "face_cascade = cv2.CascadeClassifier(\n",
    "    cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\"\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# VIDEO CAPTURE\n",
    "# ===============================\n",
    "cap = cv2.VideoCapture(IP_CAM_STREAM)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, FRAME_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, FRAME_HEIGHT)\n",
    "cap.set(cv2.CAP_PROP_FPS, TARGET_FPS)\n",
    "cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Camera open failed\")\n",
    "    exit(1)\n",
    "\n",
    "print(\"Press 'q' to quit\")\n",
    "\n",
    "# ===============================\n",
    "# TEMPORAL BUFFERS\n",
    "# ===============================\n",
    "conf_buffer = deque(maxlen=PRED_HISTORY)\n",
    "class_buffer = deque(maxlen=PRED_HISTORY)\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "# ===============================\n",
    "# MAIN LOOP\n",
    "# ===============================\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Frame read failed\")\n",
    "        break\n",
    "\n",
    "    # Rotate frame if needed\n",
    "    if ROTATE_FRAME:\n",
    "        frame = cv2.rotate(frame, ROTATE_MODE)\n",
    "\n",
    "    frame_count += 1\n",
    "\n",
    "    # Skip frames for performance\n",
    "    if frame_count % FRAME_SKIP != 0:\n",
    "        cv2.imshow(\"Face Recognition Test\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "        continue\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(\n",
    "        gray,\n",
    "        scaleFactor=1.3,\n",
    "        minNeighbors=5,\n",
    "        minSize=(80, 80)\n",
    "    )\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        face = frame[y:y+h, x:x+w]\n",
    "        face = cv2.resize(face, (IMG_SIZE, IMG_SIZE))\n",
    "        face = face.astype(\"float32\") / 255.0\n",
    "        face = np.expand_dims(face, axis=0)\n",
    "\n",
    "        preds = model.predict(face, verbose=0)[0]\n",
    "        class_id = int(np.argmax(preds))\n",
    "        confidence = float(preds[class_id])\n",
    "\n",
    "        # Append to temporal buffers\n",
    "        conf_buffer.append(confidence)\n",
    "        class_buffer.append(class_id)\n",
    "\n",
    "        avg_conf = np.mean(conf_buffer)\n",
    "        stable_class = max(set(class_buffer), key=class_buffer.count)\n",
    "\n",
    "        # Stable prediction logic\n",
    "        if avg_conf >= CONF_THRESHOLD and class_buffer.count(stable_class) >= MIN_STABLE_COUNT:\n",
    "            name = class_names.get(stable_class, \"Unknown\")\n",
    "            label = f\"{name} ({avg_conf*100:.1f}%)\"\n",
    "            color = (0, 255, 0)\n",
    "        else:\n",
    "            label = \"Unknown\"\n",
    "            color = (0, 0, 255)\n",
    "\n",
    "        # Draw bounding box and label\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "        cv2.putText(\n",
    "            frame,\n",
    "            label,\n",
    "            (x, y - 10),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.75,\n",
    "            color,\n",
    "            2\n",
    "        )\n",
    "\n",
    "    cv2.imshow(\"Face Recognition Test\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# ===============================\n",
    "# CLEANUP\n",
    "# ===============================\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1a8da23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n",
      "Loaded 540 class labels\n",
      "Found 7 images in /home/sandeshprasai/Downloads\n",
      "0007_01.jpg -> n000148 (99.94%)\n",
      "download.png -> n000273 (53.26%)\n",
      "0008_01.jpg -> n000010 (100.00%)\n",
      "download1.png -> n000008 (99.77%)\n",
      "download.jpeg -> n000008 (99.95%)\n",
      "0005_01.jpg -> n000273 (100.00%)\n",
      "0013_01.jpg -> n000008 (99.96%)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "# ================== CONFIG ==================\n",
    "MODEL_PATH = r\"/home/sandeshprasai/Final_Semester_Project/AI_Attendance_System/ai-ml-model/src/models/best_face_model.keras\"  # Change path\n",
    "LABEL_PATH = r\"/home/sandeshprasai/Final_Semester_Project/AI_Attendance_System/ai-ml-model/src/models/class_labels.json\"  # Change path\n",
    "IMG_SIZE = 112  # Must match your training\n",
    "CONF_THRESHOLD = 0.5\n",
    "DOWNLOAD_FOLDER = r\"/home/sandeshprasai/Downloads\"  # Change path if needed\n",
    "\n",
    "# ================== LOAD MODEL ==================\n",
    "# Uncomment the below line if you want to force CPU (in case GPU causes errors)\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "print(\"Model loaded successfully\")\n",
    "\n",
    "# ================== LOAD LABELS ==================\n",
    "with open(LABEL_PATH, \"r\") as f:\n",
    "    labels = json.load(f)\n",
    "\n",
    "# Correct mapping: index -> class_name\n",
    "class_names = {int(k): v for k, v in labels.items()}\n",
    "print(f\"Loaded {len(class_names)} class labels\")\n",
    "\n",
    "# ================== HELPER FUNCTION ==================\n",
    "def predict_image(image_path):\n",
    "    \"\"\"Load image, preprocess, predict, return class + confidence\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"❌ File does not exist: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"❌ Failed to read image: {image_path}\")\n",
    "        return None\n",
    "\n",
    "    # Resize & normalize\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "\n",
    "    preds = model.predict(img, verbose=0)[0]\n",
    "    class_id = int(np.argmax(preds))\n",
    "    confidence = float(preds[class_id])\n",
    "\n",
    "    if confidence >= CONF_THRESHOLD:\n",
    "        name = class_names.get(class_id, \"Unknown\")\n",
    "    else:\n",
    "        name = \"Unknown\"\n",
    "\n",
    "    return name, confidence\n",
    "\n",
    "# ================== TEST IMAGES ==================\n",
    "image_files = [f for f in os.listdir(DOWNLOAD_FOLDER)\n",
    "               if f.lower().endswith((\".jpg\", \".jpeg\", \".png\", \".bmp\"))]\n",
    "\n",
    "print(f\"Found {len(image_files)} images in {DOWNLOAD_FOLDER}\")\n",
    "\n",
    "for img_file in image_files:\n",
    "    path = os.path.join(DOWNLOAD_FOLDER, img_file)\n",
    "    result = predict_image(path)\n",
    "    if result:\n",
    "        name, conf = result\n",
    "        print(f\"{img_file} -> {name} ({conf*100:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b13f6000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings for 7 images.\n",
      "✅ Embeddings saved to face_embeddings.npy\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "\n",
    "# Create embedding model (output = dense_1)\n",
    "embedding_model = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=model.get_layer(\"dense_1\").output\n",
    ")\n",
    "\n",
    "# ================== IMAGE PREPROCESS ==================\n",
    "def preprocess_image(image_path, img_size=112):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    return img\n",
    "\n",
    "# ================== GENERATE EMBEDDINGS ==================\n",
    "embeddings_dict = {}\n",
    "\n",
    "for filename in os.listdir(DOWNLOAD_FOLDER):\n",
    "    if filename.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
    "        img_path = os.path.join(DOWNLOAD_FOLDER, filename)\n",
    "        img = preprocess_image(img_path)\n",
    "        embedding_vector = embedding_model.predict(img, verbose=0)\n",
    "        # Normalize embedding for similarity tasks\n",
    "        embedding_vector = embedding_vector / np.linalg.norm(embedding_vector)\n",
    "        embeddings_dict[filename] = embedding_vector.flatten()\n",
    "\n",
    "print(f\"Generated embeddings for {len(embeddings_dict)} images.\")\n",
    "\n",
    "# ================== SAVE EMBEDDINGS ==================\n",
    "import numpy as np\n",
    "np.save(os.path.join(DOWNLOAD_FOLDER, \"face_embeddings.npy\"), embeddings_dict)\n",
    "print(\"✅ Embeddings saved to face_embeddings.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20405c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load(\"/home/sandeshprasai/Downloads/face_embeddings.npy\", allow_pickle=True).item()\n",
    "print(data.keys())  # list all images loaded\n",
    "print(data[\"download1.png\"])  # example embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a055b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.24210279\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# embeddings for two images\n",
    "emb1 = data[\"0007_01.jpg\"]\n",
    "emb2 = data[\"0013_01.jpg\"]\n",
    "\n",
    "# normalize vectors\n",
    "emb1 = emb1 / np.linalg.norm(emb1)\n",
    "emb2 = emb2 / np.linalg.norm(emb2)\n",
    "\n",
    "# cosine similarity\n",
    "similarity = np.dot(emb1, emb2)\n",
    "print(\"Cosine similarity:\", similarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86001d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FaceEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
