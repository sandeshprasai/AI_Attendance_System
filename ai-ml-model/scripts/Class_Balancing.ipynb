{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f2482a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Aishwarya_Rai: 82 images\n",
      "Processing Akshay_Kumar: 37 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Alia_Bhatt: 60 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Allu_Arjun: 45 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Amitabh_Bachchan: 52 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Angelina_Jolie: 75 images\n",
      "Processing Ariana_Grande: 66 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Barack_Obama: 69 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Bhuwan_K.C: 57 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Billie_Eilish: 79 images\n",
      "Processing Bill_Gates: 69 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Brad_Pitt: 75 images\n",
      "Processing Chris_Evans: 77 images\n",
      "Processing Cristiano_Ronaldo: 66 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Deepika_Padukone: 77 images\n",
      "Processing Drake: 65 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Dwayne_Johnson: 86 images\n",
      "Processing Ed_Sheeran: 81 images\n",
      "Processing Emma_Watson: 96 images\n",
      "Processing Hrithik_Roshan: 65 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Jackie_Chan: 56 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Jeff_Bezos: 75 images\n",
      "Processing Jennifer_Lawrence: 98 images\n",
      "Processing Justin_Bieber: 88 images\n",
      "Processing Kamal_Haasan: 51 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Kareena_Kapoor: 49 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Kevin_Hart: 73 images\n",
      "Processing Kim_Kardashian: 95 images\n",
      "Processing Kylie_Jenner: 80 images\n",
      "Processing Leonardo_DiCaprio: 82 images\n",
      "Processing Mahesh_Babu: 51 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Mark_Zuckerberg: 76 images\n",
      "Processing Mary_Kom: 60 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Michael_Jordan: 77 images\n",
      "Processing N.T._Rama_Rao_Jr: 49 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Neymar_Jr: 67 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Oprah_Winfrey: 80 images\n",
      "Processing P.V._Sindhu: 60 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Pope_Francis: 69 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Prabhas: 43 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Priyanka_Chopra: 40 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Rajesh_Hamal: 44 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Rajinikanth: 32 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Ranbir_Kapoor: 58 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Ranveer_Singh: 52 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Rihanna: 70 images\n",
      "Processing Robert_Downey_Jr: 66 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Roger_Federer: 82 images\n",
      "Processing Sachin_Tendulkar: 68 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Salman_Khan: 59 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Scarlett_Johansson: 94 images\n",
      "Processing Selena_Gomez: 71 images\n",
      "Processing Serena_Williams: 69 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Shah_Rukh_Khan: 77 images\n",
      "Processing Shawn_Mendes: 92 images\n",
      "Processing Taylor_Swift: 65 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Tom_Holland: 68 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Vijay: 49 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Virat_Kohli: 54 images\n",
      "→ After augmentation: 70 images\n",
      "Processing Will_Smith: 101 images\n",
      "Processing Zendaya: 80 images\n",
      "✅ Dataset balanced with realistic, single-step augmentations!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Directory containing all person folders\n",
    "faces_dir = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\AI_And_ML_Model\\data\\faces\"\n",
    "\n",
    "# Target number of images per class\n",
    "target_images = 70\n",
    "\n",
    "# Augmentation options\n",
    "rotation_angles = [-15, -10, -5, 5, 10, 15]\n",
    "brightness_factors = [0.7, 0.85, 1.15, 1.3]\n",
    "zoom_factors = [0.9, 0.95, 1.05, 1.1]\n",
    "shift_pixels = [-10, -5, 5, 10]  # horizontal/vertical shift in pixels\n",
    "noise_std = 10  # standard deviation for Gaussian noise\n",
    "\n",
    "def augment_image(img, method):\n",
    "    \"\"\"Apply one augmentation method to the image.\"\"\"\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    if method == \"flip\":\n",
    "        return cv2.flip(img, 1)\n",
    "\n",
    "    elif method == \"rotate\":\n",
    "        angle = random.choice(rotation_angles)\n",
    "        M = cv2.getRotationMatrix2D((w//2, h//2), angle, 1.0)\n",
    "        return cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "    elif method == \"brightness\":\n",
    "        factor = random.choice(brightness_factors)\n",
    "        return cv2.convertScaleAbs(img, alpha=factor, beta=0)\n",
    "\n",
    "    elif method == \"zoom\":\n",
    "        factor = random.choice(zoom_factors)\n",
    "        new_w, new_h = int(w*factor), int(h*factor)\n",
    "        resized = cv2.resize(img, (new_w, new_h))\n",
    "        if factor > 1.0:\n",
    "            # crop center\n",
    "            start_x = (new_w - w)//2\n",
    "            start_y = (new_h - h)//2\n",
    "            return resized[start_y:start_y+h, start_x:start_x+w]\n",
    "        else:\n",
    "            # pad with black\n",
    "            padded = np.zeros_like(img)\n",
    "            start_x = (w - new_w)//2\n",
    "            start_y = (h - new_h)//2\n",
    "            padded[start_y:start_y+new_h, start_x:start_x+new_w] = resized\n",
    "            return padded\n",
    "\n",
    "    elif method == \"shift\":\n",
    "        tx = random.choice(shift_pixels)\n",
    "        ty = random.choice(shift_pixels)\n",
    "        M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "        return cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "    # elif method == \"noise\":\n",
    "    #     noise = np.random.normal(0, noise_std, img.shape).astype(np.uint8)\n",
    "    #     noisy = cv2.add(img, noise)\n",
    "    #     return noisy\n",
    "\n",
    "    else:\n",
    "        return img  # no augmentation\n",
    "\n",
    "# Available augmentation methods\n",
    "methods = [\"flip\", \"rotate\", \"brightness\", \"zoom\", \"shift\", \"noise\"]\n",
    "\n",
    "# Loop through each person folder\n",
    "for person_name in os.listdir(faces_dir):\n",
    "    person_path = os.path.join(faces_dir, person_name)\n",
    "    if not os.path.isdir(person_path):\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(person_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "    num_images = len(images)\n",
    "\n",
    "    print(f\"Processing {person_name}: {num_images} images\")\n",
    "\n",
    "    if num_images >= target_images:\n",
    "        continue\n",
    "\n",
    "    needed = target_images - num_images\n",
    "    idx = 0\n",
    "\n",
    "    while needed > 0:\n",
    "        img_name = images[idx % len(images)]\n",
    "        img_path = os.path.join(person_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            idx += 1\n",
    "            continue\n",
    "\n",
    "        # Randomly pick one augmentation method\n",
    "        method = random.choice(methods)\n",
    "        aug_img = augment_image(img, method)\n",
    "\n",
    "        out_name = f\"{os.path.splitext(img_name)[0]}_aug{num_images}.jpg\"\n",
    "        out_path = os.path.join(person_path, out_name)\n",
    "        cv2.imwrite(out_path, aug_img)\n",
    "\n",
    "        num_images += 1\n",
    "        needed -= 1\n",
    "        idx += 1\n",
    "\n",
    "    print(f\"→ After augmentation: {num_images} images\")\n",
    "\n",
    "print(\"✅ Dataset balanced with realistic, single-step augmentations!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2e9259",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
