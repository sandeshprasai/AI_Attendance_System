{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8472e30-33c3-4710-a154-ab30cb50248e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Total images found: 40600\n",
      "Train: 28420  Val: 6090  Test: 6090\n",
      "Found 28420 validated image filenames belonging to 58 classes.\n",
      "Found 6090 validated image filenames belonging to 58 classes.\n",
      "Found 6090 validated image filenames belonging to 58 classes.\n",
      "Number of classes: 58\n",
      "Epoch 1/50\n",
      "1777/1777 [==============================] - 416s 230ms/step - loss: 4.1759 - accuracy: 0.0330 - val_loss: 4.0879 - val_accuracy: 0.0356 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "1777/1777 [==============================] - 323s 182ms/step - loss: 3.8130 - accuracy: 0.0796 - val_loss: 3.4196 - val_accuracy: 0.1304 - lr: 5.0000e-04\n",
      "Epoch 3/50\n",
      "1777/1777 [==============================] - 324s 182ms/step - loss: 3.3836 - accuracy: 0.1457 - val_loss: 3.3812 - val_accuracy: 0.1463 - lr: 5.0000e-04\n",
      "Epoch 4/50\n",
      "1777/1777 [==============================] - 324s 182ms/step - loss: 2.9428 - accuracy: 0.2357 - val_loss: 2.5224 - val_accuracy: 0.3255 - lr: 5.0000e-04\n",
      "Epoch 5/50\n",
      "1777/1777 [==============================] - 324s 182ms/step - loss: 2.4927 - accuracy: 0.3445 - val_loss: 2.1676 - val_accuracy: 0.4519 - lr: 5.0000e-04\n",
      "Epoch 6/50\n",
      "1777/1777 [==============================] - 324s 183ms/step - loss: 2.0906 - accuracy: 0.4614 - val_loss: 1.8788 - val_accuracy: 0.5323 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.7784 - accuracy: 0.5618 - val_loss: 1.3237 - val_accuracy: 0.6915 - lr: 5.0000e-04\n",
      "Epoch 8/50\n",
      "1777/1777 [==============================] - 335s 188ms/step - loss: 1.5402 - accuracy: 0.6352 - val_loss: 1.1937 - val_accuracy: 0.7402 - lr: 5.0000e-04\n",
      "Epoch 9/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.3624 - accuracy: 0.6982 - val_loss: 0.9553 - val_accuracy: 0.8167 - lr: 5.0000e-04\n",
      "Epoch 10/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.2525 - accuracy: 0.7405 - val_loss: 0.8821 - val_accuracy: 0.8544 - lr: 5.0000e-04\n",
      "Epoch 11/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.1574 - accuracy: 0.7759 - val_loss: 0.8363 - val_accuracy: 0.8713 - lr: 5.0000e-04\n",
      "Epoch 12/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.0937 - accuracy: 0.8041 - val_loss: 0.7925 - val_accuracy: 0.8956 - lr: 5.0000e-04\n",
      "Epoch 13/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.0439 - accuracy: 0.8209 - val_loss: 0.7111 - val_accuracy: 0.9289 - lr: 5.0000e-04\n",
      "Epoch 14/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 1.0030 - accuracy: 0.8409 - val_loss: 1.0419 - val_accuracy: 0.8427 - lr: 5.0000e-04\n",
      "Epoch 15/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.9854 - accuracy: 0.8495 - val_loss: 0.7244 - val_accuracy: 0.9300 - lr: 5.0000e-04\n",
      "Epoch 16/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.9553 - accuracy: 0.8656 - val_loss: 0.6691 - val_accuracy: 0.9496 - lr: 5.0000e-04\n",
      "Epoch 17/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.9422 - accuracy: 0.8740 - val_loss: 0.6759 - val_accuracy: 0.9544 - lr: 5.0000e-04\n",
      "Epoch 18/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.9280 - accuracy: 0.8774 - val_loss: 0.6951 - val_accuracy: 0.9519 - lr: 5.0000e-04\n",
      "Epoch 19/50\n",
      "1777/1777 [==============================] - 326s 183ms/step - loss: 0.9239 - accuracy: 0.8828 - val_loss: 0.6413 - val_accuracy: 0.9695 - lr: 5.0000e-04\n",
      "Epoch 20/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.8933 - accuracy: 0.8952 - val_loss: 0.6543 - val_accuracy: 0.9677 - lr: 5.0000e-04\n",
      "Epoch 21/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.8900 - accuracy: 0.8983 - val_loss: 0.6528 - val_accuracy: 0.9695 - lr: 5.0000e-04\n",
      "Epoch 22/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.8884 - accuracy: 0.9010 - val_loss: 0.6654 - val_accuracy: 0.9667 - lr: 5.0000e-04\n",
      "Epoch 23/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.8861 - accuracy: 0.9033 - val_loss: 0.6627 - val_accuracy: 0.9698 - lr: 5.0000e-04\n",
      "Epoch 24/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.8661 - accuracy: 0.9098 - val_loss: 0.7973 - val_accuracy: 0.9278 - lr: 5.0000e-04\n",
      "Epoch 25/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.7395 - accuracy: 0.9453 - val_loss: 0.5773 - val_accuracy: 0.9923 - lr: 1.5000e-04\n",
      "Epoch 26/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.6860 - accuracy: 0.9559 - val_loss: 0.5692 - val_accuracy: 0.9908 - lr: 1.5000e-04\n",
      "Epoch 27/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.6524 - accuracy: 0.9621 - val_loss: 0.5398 - val_accuracy: 0.9934 - lr: 1.5000e-04\n",
      "Epoch 28/50\n",
      "1777/1777 [==============================] - 326s 183ms/step - loss: 0.6293 - accuracy: 0.9635 - val_loss: 0.5221 - val_accuracy: 0.9947 - lr: 1.5000e-04\n",
      "Epoch 29/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.6101 - accuracy: 0.9655 - val_loss: 0.5152 - val_accuracy: 0.9921 - lr: 1.5000e-04\n",
      "Epoch 30/50\n",
      "1777/1777 [==============================] - 399s 225ms/step - loss: 0.5932 - accuracy: 0.9669 - val_loss: 0.4918 - val_accuracy: 0.9954 - lr: 1.5000e-04\n",
      "Epoch 31/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.5768 - accuracy: 0.9677 - val_loss: 0.4777 - val_accuracy: 0.9961 - lr: 1.5000e-04\n",
      "Epoch 32/50\n",
      "1777/1777 [==============================] - 326s 183ms/step - loss: 0.5594 - accuracy: 0.9697 - val_loss: 0.4826 - val_accuracy: 0.9911 - lr: 1.5000e-04\n",
      "Epoch 33/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.5468 - accuracy: 0.9694 - val_loss: 0.4564 - val_accuracy: 0.9947 - lr: 1.5000e-04\n",
      "Epoch 34/50\n",
      "1777/1777 [==============================] - 451s 254ms/step - loss: 0.5318 - accuracy: 0.9710 - val_loss: 0.4477 - val_accuracy: 0.9952 - lr: 1.5000e-04\n",
      "Epoch 35/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.5202 - accuracy: 0.9723 - val_loss: 0.4415 - val_accuracy: 0.9946 - lr: 1.5000e-04\n",
      "Epoch 36/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.5067 - accuracy: 0.9718 - val_loss: 0.4278 - val_accuracy: 0.9949 - lr: 1.5000e-04\n",
      "Epoch 37/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4921 - accuracy: 0.9741 - val_loss: 0.4145 - val_accuracy: 0.9970 - lr: 1.5000e-04\n",
      "Epoch 38/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4860 - accuracy: 0.9741 - val_loss: 0.4122 - val_accuracy: 0.9949 - lr: 1.5000e-04\n",
      "Epoch 39/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4827 - accuracy: 0.9724 - val_loss: 0.4057 - val_accuracy: 0.9947 - lr: 1.5000e-04\n",
      "Epoch 40/50\n",
      "1777/1777 [==============================] - 397s 223ms/step - loss: 0.4687 - accuracy: 0.9748 - val_loss: 0.3920 - val_accuracy: 0.9969 - lr: 1.5000e-04\n",
      "Epoch 41/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4641 - accuracy: 0.9730 - val_loss: 0.3886 - val_accuracy: 0.9964 - lr: 1.5000e-04\n",
      "Epoch 42/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4525 - accuracy: 0.9757 - val_loss: 0.3783 - val_accuracy: 0.9966 - lr: 1.5000e-04\n",
      "Epoch 43/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4470 - accuracy: 0.9761 - val_loss: 0.3763 - val_accuracy: 0.9938 - lr: 1.5000e-04\n",
      "Epoch 44/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4400 - accuracy: 0.9752 - val_loss: 0.3685 - val_accuracy: 0.9957 - lr: 1.5000e-04\n",
      "Epoch 45/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4311 - accuracy: 0.9764 - val_loss: 0.3619 - val_accuracy: 0.9959 - lr: 1.5000e-04\n",
      "Epoch 46/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4266 - accuracy: 0.9768 - val_loss: 0.3596 - val_accuracy: 0.9943 - lr: 1.5000e-04\n",
      "Epoch 47/50\n",
      "1777/1777 [==============================] - 325s 183ms/step - loss: 0.4207 - accuracy: 0.9758 - val_loss: 0.3508 - val_accuracy: 0.9966 - lr: 1.5000e-04\n",
      "Epoch 48/50\n",
      "1777/1777 [==============================] - 358s 201ms/step - loss: 0.4129 - accuracy: 0.9761 - val_loss: 0.3489 - val_accuracy: 0.9951 - lr: 1.5000e-04\n",
      "Epoch 49/50\n",
      "1777/1777 [==============================] - 328s 184ms/step - loss: 0.4112 - accuracy: 0.9754 - val_loss: 0.3392 - val_accuracy: 0.9959 - lr: 1.5000e-04\n",
      "Epoch 50/50\n",
      "1777/1777 [==============================] - 327s 184ms/step - loss: 0.4075 - accuracy: 0.9754 - val_loss: 0.3363 - val_accuracy: 0.9957 - lr: 1.5000e-04\n",
      "381/381 [==============================] - 87s 229ms/step - loss: 0.3351 - accuracy: 0.9961\n",
      "Test accuracy: 0.9960591197013855\n",
      "Model + labels saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# -----------------------------\n",
    "# GPU Setup\n",
    "# -----------------------------\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[0], 'GPU')\n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "        device = '/GPU:0'\n",
    "        print(f\"Using GPU: {gpus[0]}\")\n",
    "    except:\n",
    "        device = '/CPU:0'\n",
    "else:\n",
    "    device = '/CPU:0'\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# -----------------------------\n",
    "# Dataset Path (Single Folder)\n",
    "# -----------------------------\n",
    "dataset_dir = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\AI_And_ML_Model\\DataSets\\RecognizeAgumented\"\n",
    "\n",
    "# -----------------------------\n",
    "# Create DataFrame of Images\n",
    "# -----------------------------\n",
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for label in os.listdir(dataset_dir):\n",
    "    class_dir = os.path.join(dataset_dir, label)\n",
    "    if os.path.isdir(class_dir):\n",
    "        for file in os.listdir(class_dir):\n",
    "            filepaths.append(os.path.join(class_dir, file))\n",
    "            labels.append(label)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filepath': filepaths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(\"Total images found:\", len(df))\n",
    "\n",
    "# -----------------------------\n",
    "# Split dataset (sklearn)\n",
    "# -----------------------------\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['label'], random_state=42)\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(\"Train:\", len(train_df), \" Val:\", len(val_df), \" Test:\", len(test_df))\n",
    "\n",
    "# -----------------------------\n",
    "# Generators\n",
    "# -----------------------------\n",
    "img_size = (224, 224)\n",
    "batch_size = 16\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_gen = datagen.flow_from_dataframe(\n",
    "    train_df, x_col='filepath', y_col='label',\n",
    "    target_size=img_size, class_mode='categorical', batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_dataframe(\n",
    "    val_df, x_col='filepath', y_col='label',\n",
    "    target_size=img_size, class_mode='categorical', batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_gen = datagen.flow_from_dataframe(\n",
    "    test_df, x_col='filepath', y_col='label',\n",
    "    target_size=img_size, class_mode='categorical', batch_size=batch_size, shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "# -----------------------------\n",
    "# Model\n",
    "# -----------------------------\n",
    "checkpoint_path = \"checkpoints/best_model.keras\"\n",
    "weight_decay = 1e-4\n",
    "\n",
    "with tf.device(device):\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        print(\"Loading checkpoint model…\")\n",
    "        model = load_model(checkpoint_path)\n",
    "    else:\n",
    "        inputs = Input(shape=(224, 224, 3))\n",
    "        \n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(inputs)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(32, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(64, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        x = Dropout(0.3)(x)\n",
    "\n",
    "        x = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(128, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "        x = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Conv2D(256, (3,3), activation='relu', padding='same', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = MaxPooling2D(2,2)(x)\n",
    "        x = Dropout(0.4)(x)\n",
    "\n",
    "        x = GlobalAveragePooling2D()(x)\n",
    "        x = Dense(512, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = Dropout(0.6)(x)\n",
    "        x = Dense(256, activation='relu', kernel_regularizer=l2(weight_decay))(x)\n",
    "        x = Dropout(0.6)(x)\n",
    "\n",
    "        outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "        model = Model(inputs, outputs)\n",
    "\n",
    "        model.compile(\n",
    "            optimizer=Adam(0.0005),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "# -----------------------------\n",
    "# Callbacks\n",
    "# -----------------------------\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=5, factor=0.3)\n",
    "checkpoint = ModelCheckpoint(checkpoint_path, save_best_only=True, monitor='val_loss')\n",
    "\n",
    "# -----------------------------\n",
    "# Train\n",
    "# -----------------------------\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=50,\n",
    "                    callbacks=[early_stop, reduce_lr, checkpoint])\n",
    "\n",
    "# -----------------------------\n",
    "# Test Evaluation\n",
    "# -----------------------------\n",
    "test_loss, test_acc = model.evaluate(test_gen)\n",
    "print(\"Test accuracy:\", test_acc)\n",
    "\n",
    "# -----------------------------\n",
    "# Save final model & labels\n",
    "# -----------------------------\n",
    "model.save(\"face_recognition_attendance_final.keras\")\n",
    "model.save(\"face_recognition_attendance_final.h5\")\n",
    "\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(train_gen.class_indices, f)\n",
    "\n",
    "print(\"Model + labels saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7329af-6fd7-47e4-ae6e-69c49f1d8b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "381/381 [==============================] - 16s 41ms/step\n",
      "✔ Saved: confusion_matrix.png\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "     Aishwarya_Rai       1.00      0.99      1.00       105\n",
      "      Akshay_Kumar       0.99      1.00      1.00       105\n",
      "        Alia_Bhatt       1.00      0.99      1.00       105\n",
      "        Allu_Arjun       0.99      1.00      1.00       105\n",
      "  Amitabh_Bachchan       1.00      1.00      1.00       105\n",
      "    Angelina_Jolie       1.00      0.99      1.00       105\n",
      "     Ariana_Grande       0.99      1.00      1.00       105\n",
      "      Barack_Obama       1.00      1.00      1.00       105\n",
      "        Bill_Gates       1.00      1.00      1.00       105\n",
      "         Brad_Pitt       1.00      0.97      0.99       105\n",
      "       Chris_Evans       0.99      1.00      1.00       105\n",
      " Cristiano_Ronaldo       1.00      1.00      1.00       105\n",
      "  Deepika_Padukone       0.99      1.00      1.00       105\n",
      "             Drake       1.00      0.98      0.99       105\n",
      "    Dwayne_Johnson       1.00      1.00      1.00       105\n",
      "        Ed_Sheeran       1.00      1.00      1.00       105\n",
      "       Emma_Watson       1.00      1.00      1.00       105\n",
      "    Hrithik_Roshan       1.00      0.98      0.99       105\n",
      "       Jackie_Chan       1.00      0.98      0.99       105\n",
      "        Jeff_Bezos       1.00      1.00      1.00       105\n",
      " Jennifer_Lawrence       1.00      1.00      1.00       105\n",
      "     Justin_Bieber       0.99      1.00      1.00       105\n",
      "      Kamal_Haasan       1.00      1.00      1.00       105\n",
      "  Kanchan Shrestha       1.00      1.00      1.00       105\n",
      "    Kareena_Kapoor       1.00      1.00      1.00       105\n",
      "        Kevin_Hart       1.00      1.00      1.00       105\n",
      "    Kim_Kardashian       0.99      1.00      1.00       105\n",
      "      Kiran Dhakal       1.00      1.00      1.00       105\n",
      "      Kylie_Jenner       0.97      0.99      0.98       105\n",
      " Leonardo_DiCaprio       1.00      0.99      1.00       105\n",
      "   Mark_Zuckerberg       0.98      0.99      0.99       105\n",
      "          Mary_Kom       1.00      1.00      1.00       105\n",
      "    Michael_Jordan       1.00      1.00      1.00       105\n",
      "         Neymar_Jr       0.99      1.00      1.00       105\n",
      "     Oprah_Winfrey       1.00      1.00      1.00       105\n",
      "       P.V._Sindhu       1.00      1.00      1.00       105\n",
      "      Pope_Francis       0.98      1.00      0.99       105\n",
      "           Prabhas       1.00      1.00      1.00       105\n",
      "   Priyanka_Chopra       1.00      0.97      0.99       105\n",
      "     Ranbir_Kapoor       1.00      1.00      1.00       105\n",
      "     Ranveer_Singh       1.00      0.99      1.00       105\n",
      "           Rihanna       0.99      1.00      1.00       105\n",
      "  Robert_Downey_Jr       0.97      0.99      0.98       105\n",
      "     Roger_Federer       0.98      1.00      0.99       105\n",
      "  Sachin_Tendulkar       1.00      1.00      1.00       105\n",
      "       Salman_Khan       1.00      0.98      0.99       105\n",
      "            Saloni       1.00      1.00      1.00       105\n",
      "    Sandesh Prasai       0.99      1.00      1.00       105\n",
      "Scarlett_Johansson       1.00      1.00      1.00       105\n",
      "      Selena_Gomez       1.00      1.00      1.00       105\n",
      "   Serena_Williams       1.00      1.00      1.00       105\n",
      "    Shah_Rukh_Khan       1.00      1.00      1.00       105\n",
      "      Shawn_Mendes       1.00      1.00      1.00       105\n",
      "      Taylor_Swift       1.00      0.98      0.99       105\n",
      "       Tom_Holland       1.00      1.00      1.00       105\n",
      "       Virat_Kohli       1.00      1.00      1.00       105\n",
      "        Will_Smith       1.00      1.00      1.00       105\n",
      "           Zendaya       0.98      1.00      0.99       105\n",
      "\n",
      "          accuracy                           1.00      6090\n",
      "         macro avg       1.00      1.00      1.00      6090\n",
      "      weighted avg       1.00      1.00      1.00      6090\n",
      "\n",
      "✔ Saved: classification_report.txt\n",
      "✔ Saved: precision_curve.png\n",
      "✔ Saved: recall_curve.png\n",
      "✔ Saved: precision_recall_curve.png\n",
      "✔ Saved: roc_curve.png\n",
      "✔ Saved: auc_metrics.json\n",
      "\n",
      "All plots and metrics are saved in the 'plots/' folder.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, precision_recall_curve,\n",
    "    roc_curve, auc\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Create folder for saving plots\n",
    "# ---------------------------------------------------------\n",
    "plot_dir = \"plots\"\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Predictions\n",
    "# ---------------------------------------------------------\n",
    "y_true = test_gen.classes\n",
    "y_pred_prob = model.predict(test_gen)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "class_names = list(test_gen.class_indices.keys())\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Binarize true labels\n",
    "y_true_bin = label_binarize(y_true, classes=list(range(num_classes)))\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CONFUSION MATRIX\n",
    "# ---------------------------------------------------------\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap=\"Blues\",\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/confusion_matrix.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✔ Saved: confusion_matrix.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# CLASSIFICATION REPORT (Precision, Recall, F1)\n",
    "# ---------------------------------------------------------\n",
    "report = classification_report(y_true, y_pred, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)\n",
    "\n",
    "with open(f\"{plot_dir}/classification_report.txt\", \"w\") as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(\"✔ Saved: classification_report.txt\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PRECISION CURVE (per class)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(num_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    plt.plot(precision, label=f\"{class_names[i]}\")\n",
    "\n",
    "plt.title(\"Precision Curve\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/precision_curve.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✔ Saved: precision_curve.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RECALL CURVE (per class)\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(num_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    plt.plot(recall, label=f\"{class_names[i]}\")\n",
    "\n",
    "plt.title(\"Recall Curve\")\n",
    "plt.xlabel(\"Threshold\")\n",
    "plt.ylabel(\"Recall\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/recall_curve.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✔ Saved: recall_curve.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# PRECISION-RECALL CURVE\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "for i in range(num_classes):\n",
    "    precision, recall, _ = precision_recall_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    plt.plot(recall, precision, label=f\"{class_names[i]}\")\n",
    "\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.xlabel(\"Recall\")\n",
    "plt.ylabel(\"Precision\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/precision_recall_curve.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✔ Saved: precision_recall_curve.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ROC CURVE + AUC Combined Metrics\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "macro_auc_list = []\n",
    "micro_y_true = y_true_bin.ravel()\n",
    "micro_y_prob = y_pred_prob.ravel()\n",
    "\n",
    "for i in range(num_classes):\n",
    "    fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_prob[:, i])\n",
    "    roc_auc_class = auc(fpr, tpr)\n",
    "    macro_auc_list.append(roc_auc_class)\n",
    "    \n",
    "    plt.plot(fpr, tpr, label=f\"{class_names[i]} (AUC = {roc_auc_class:.3f})\")\n",
    "\n",
    "# MICRO AUC\n",
    "fpr_micro, tpr_micro, _ = roc_curve(micro_y_true, micro_y_prob)\n",
    "auc_micro = auc(fpr_micro, tpr_micro)\n",
    "\n",
    "# MACRO AUC (average of per-class AUCs)\n",
    "auc_macro = np.mean(macro_auc_list)\n",
    "\n",
    "# Plot diagonal line\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "\n",
    "plt.title(\"ROC Curve (One-vs-Rest)\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(f\"{plot_dir}/roc_curve.png\", dpi=300)\n",
    "plt.close()\n",
    "\n",
    "print(\"✔ Saved: roc_curve.png\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# SAVE AUC METRICS\n",
    "# ---------------------------------------------------------\n",
    "auc_data = {\n",
    "    \"AUC Micro\": auc_micro,\n",
    "    \"AUC Macro\": auc_macro,\n",
    "    \"AUC Per Class\": {class_names[i]: float(macro_auc_list[i]) for i in range(num_classes)}\n",
    "}\n",
    "\n",
    "with open(f\"{plot_dir}/auc_metrics.json\", \"w\") as f:\n",
    "    json.dump(auc_data, f, indent=4)\n",
    "\n",
    "print(\"✔ Saved: auc_metrics.json\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# Summary\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nAll plots and metrics are saved in the 'plots/' folder.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "000b33c9-9fdc-4393-8d49-4ff896c593e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded class labels: ['Aishwarya_Rai', 'Akshay_Kumar', 'Alia_Bhatt', 'Allu_Arjun', 'Amitabh_Bachchan', 'Angelina_Jolie', 'Ariana_Grande', 'Barack_Obama', 'Bill_Gates', 'Brad_Pitt', 'Chris_Evans', 'Cristiano_Ronaldo', 'Deepika_Padukone', 'Drake', 'Dwayne_Johnson', 'Ed_Sheeran', 'Emma_Watson', 'Hrithik_Roshan', 'Jackie_Chan', 'Jeff_Bezos', 'Jennifer_Lawrence', 'Justin_Bieber', 'Kamal_Haasan', 'Kanchan Shrestha', 'Kareena_Kapoor', 'Kevin_Hart', 'Kim_Kardashian', 'Kiran Dhakal', 'Kylie_Jenner', 'Leonardo_DiCaprio', 'Mark_Zuckerberg', 'Mary_Kom', 'Michael_Jordan', 'Neymar_Jr', 'Oprah_Winfrey', 'P.V._Sindhu', 'Pope_Francis', 'Prabhas', 'Priyanka_Chopra', 'Ranbir_Kapoor', 'Ranveer_Singh', 'Rihanna', 'Robert_Downey_Jr', 'Roger_Federer', 'Sachin_Tendulkar', 'Salman_Khan', 'Saloni', 'Sandesh Prasai', 'Scarlett_Johansson', 'Selena_Gomez', 'Serena_Williams', 'Shah_Rukh_Khan', 'Shawn_Mendes', 'Taylor_Swift', 'Tom_Holland', 'Virat_Kohli', 'Will_Smith', 'Zendaya']\n",
      "Loading model...\n",
      "Model loaded successfully!\n",
      "Press 'q' to quit.\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import json\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD CLASS LABELS\n",
    "# ----------------------------\n",
    "with open(\"class_labels.json\", \"r\") as f:\n",
    "    class_names = json.load(f)\n",
    "print(\"Loaded class labels:\", class_names)\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD MODEL\n",
    "# ----------------------------\n",
    "print(\"Loading model...\")\n",
    "model = load_model(\"face_recognition_attendance_final.keras\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Model input size (same as training)\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD FACE DETECTOR\n",
    "# ----------------------------\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \n",
    "                                     \"haarcascade_frontalface_default.xml\")\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIDENCE THRESHOLD\n",
    "# ----------------------------\n",
    "CONF_THRESHOLD = 0.7  # 70%\n",
    "\n",
    "# ----------------------------\n",
    "# START CAMERA\n",
    "# ----------------------------\n",
    "cap = cv2.VideoCapture(\"http://10.61.200.79:4747/video\")\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"❌ Error: Could not open webcam\")\n",
    "    exit()\n",
    "\n",
    "print(\"Press 'q' to quit.\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"❌ Failed to read frame\")\n",
    "        break\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        # Draw face boundary\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        # Crop the face\n",
    "        face_roi = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Preprocess face\n",
    "        face_rgb = cv2.cvtColor(face_roi, cv2.COLOR_BGR2RGB)\n",
    "        face_resized = cv2.resize(face_rgb, IMG_SIZE)\n",
    "        face_array = np.expand_dims(face_resized / 255.0, axis=0)\n",
    "\n",
    "        # Predict\n",
    "        preds = model.predict(face_array)\n",
    "        class_index = np.argmax(preds)\n",
    "        confidence = float(preds[0][class_index])\n",
    "\n",
    "        # Check confidence\n",
    "        if confidence >= CONF_THRESHOLD:\n",
    "            predicted_person = class_names[class_index]\n",
    "            text = f\"{predicted_person} ({confidence*100:.1f}%)\"\n",
    "        else:\n",
    "            predicted_person = \"Unknown\"\n",
    "            text = f\"{predicted_person}\"\n",
    "\n",
    "        # Display text above face\n",
    "        cv2.putText(frame, text, (x, y - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8,\n",
    "                    (0, 0, 255) if predicted_person == \"Unknown\" else (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow(\"AI Attendance - Face Recognition\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "120d48be-6413-4213-b25f-3a73af77ba4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_labels.json created successfully!\n",
      "Total classes: 58\n",
      "['Aishwarya_Rai', 'Akshay_Kumar', 'Alia_Bhatt', 'Allu_Arjun', 'Amitabh_Bachchan', 'Angelina_Jolie', 'Ariana_Grande', 'Barack_Obama', 'Bill_Gates', 'Brad_Pitt', 'Chris_Evans', 'Cristiano_Ronaldo', 'Deepika_Padukone', 'Drake', 'Dwayne_Johnson', 'Ed_Sheeran', 'Emma_Watson', 'Hrithik_Roshan', 'Jackie_Chan', 'Jeff_Bezos', 'Jennifer_Lawrence', 'Justin_Bieber', 'Kamal_Haasan', 'Kanchan Shrestha', 'Kareena_Kapoor', 'Kevin_Hart', 'Kim_Kardashian', 'Kiran Dhakal', 'Kylie_Jenner', 'Leonardo_DiCaprio', 'Mark_Zuckerberg', 'Mary_Kom', 'Michael_Jordan', 'Neymar_Jr', 'Oprah_Winfrey', 'P.V._Sindhu', 'Pope_Francis', 'Prabhas', 'Priyanka_Chopra', 'Ranbir_Kapoor', 'Ranveer_Singh', 'Rihanna', 'Robert_Downey_Jr', 'Roger_Federer', 'Sachin_Tendulkar', 'Salman_Khan', 'Saloni', 'Sandesh Prasai', 'Scarlett_Johansson', 'Selena_Gomez', 'Serena_Williams', 'Shah_Rukh_Khan', 'Shawn_Mendes', 'Taylor_Swift', 'Tom_Holland', 'Virat_Kohli', 'Will_Smith', 'Zendaya']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# Path to your dataset folder\n",
    "dataset_path = r\"D:\\Final_Semester_Project\\AI_Attendance_System\\AI_And_ML_Model\\DataSets\\RecognizeAgumented\"\n",
    "  # change if different (ex: datasets/train)\n",
    "\n",
    "# Collect class folders\n",
    "class_names = sorted(os.listdir(dataset_path))\n",
    "\n",
    "# Save to JSON\n",
    "with open(\"class_labels.json\", \"w\") as f:\n",
    "    json.dump(class_names, f, indent=4)\n",
    "\n",
    "print(\"class_labels.json created successfully!\")\n",
    "print(f\"Total classes: {len(class_names)}\")\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19850e-2567-4ce3-84d9-cf02afe226d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (MyVenv)",
   "language": "python",
   "name": "myvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
